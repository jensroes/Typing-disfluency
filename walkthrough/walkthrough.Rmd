---
title: "Walkthrough: fitting a mixture model on copy-task data"
author: ""
date: "Compiled `r Sys.Date()`"
bibliography: ../rmarkdown/ref.bib
csl: ../rmarkdown/apa.csl
link-citations: yes
output:
  rmdformats::readthedown:
    lightbox: true
    gallery: false
    highlight: "pygments"
    toc_depth: 3
    use_bookdown: false

---

```{r, include=FALSE}
#library(citr) # ALT + Shift + R for citations
#library(kableExtra)
library(rmdformats)
library(knitr)
library(tidyverse)
library(rstan)
```

```{r setup, include=FALSE}
opts_chunk$set(fig.width = 8, fig.height = 4.5)
opts_knit$set(width=90)
knitr::opts_chunk$set(echo = TRUE,
                      comment = NA, 
                      warning = FALSE,
                      message = FALSE)
theme_set(theme_bw())
```


This walk through describes how to fit a finite mixture model of two log-Normal distributions using the statistical program R and the `rstan` package to interface with the probabilistic programming language Stan [@carpenter2016stan; @hoffman2014no; @rstan; @rstan2].^[An alternative to writing models in Stan is the R package `brms` which provides a flexible framework to implement mixture models and many other types of probability models [@burkner2017brms; @R-brms_b]. In particular, `brms` has a `mixture` function to specify mixture of various types of distributions. This could also be Gaussians, skewed-Normal, shifted-Normal, ex-Gaussian etc. and combinations of those. There is a large number of probability models for continuous data that are plausible candidates [for reaction time data see e.g. @matzke2009psychological]. ]

We require two packages: (1) `rstan` to use R to inface with Stan for fitting Bayesian models; (2) `tidyverse` for data processing and visualisation.

```{r eval = F}
library(rstan)
library(tidyverse)
```

# Fitting the model

## Preparing the data

First we load the keystroke data used in the manuscript. Data can be downloaded from [OSF](https://osf.io/y3p4d/) using the URL as below and the `read_csv` function. For brevity we use a subset of the sample. Data are from participants that each completed the consonants and LF-bigrams component of the copy task [@van2019multilingual; @waes2019]. 



```{r}
data <- read_csv("https://osf.io/e5gy6/download") %>%
  filter(ppts %in% 1:50, IKI > 10) # take first 50 ppts and only IKIs larger than 10 msecs
```


We reduced the data to four variables: a participant identifier `ppts`, a bigram identifier `bigram`, the inter-keystroke interval `IKI`, and the copy task `component` (levels: Consonants, LF).

```{r}
data
```


The data must be transformed into a list to feed them into Stan. The information required from the data is determined in the Stan code and has to do with what we need to estimate the model parameters and how the model is implemented. The exert from the Stan code below shows which information is expected as input (e.g. int is integer), how they are named, and what the smallest (i.e. lower) and largest possible value (i.e. upper) are.

```{r eval=F, engine='Rcpp'}
// Do not run
// Data chunk of Stan code
data {
  int<lower=1> N;                    // number of observations
  int<lower=1> nS;                   // number of pptsects
  int<lower=1, upper=nS> ppts[N];    // ppts identifier
  int<lower=1> nB;                   // max number of bigrams
  int<lower=1, upper=nB> bigrams[N]; // ppts identifier
  int<lower=1> K;                    //number of conditions
  int condition[N];                  // condition identifiers
  vector[N] y;                       //outcome
}
```


Depending on the data we might have different numbers of participants, bigrams, and conditions. The Stan code is using indices to be able to fit varying numbers for each. In the code below we use `factor` in combination with `as.numeric` to ensure that there are no empty indices. We create vectors with participant identifiers `ppts` (numbers $1$ through $I$ where $I$ is the number of participants), bigram identifiers `bigrams` (numbers 1 through $J$ where $J$ is the maximum number of bigrams), and a numeric identifier `components` for each copy task component (levels: consonants = 1, LF = 2).  The returned values are indices for the parameters in the model: For example, for the components identifier, `beta[1]` is the population estimate for non-hesitant typing in the consonants task, `beta[2]` is same for LF-bigram; `theta[1]` and `theta[2]` are the disfluency probability for the consonants and LF-bigrams task, respectively.

```{r}
ppts <- as.numeric(factor(data$ppts))
bigrams <- as.numeric(factor(data$bigram))
components <- as.numeric(factor(data$component))
```

In the below code, the names on the left side of the arrow must correspond to the names expected in the Stan code (above); names on the right side do not. We assign the participant, bigram, and component identifiers created above and their maximum values `nS`, `nB`, `K`, respectively. The keystroke data `IKI` are assigned to `y` and the total number of observations (number of participants $\times$ number of bigrams produced by participant) is assigned to `N` (number of rows in the data `nrow(data`).

```{r}
data_list <- within( list(), {
  ppts <- ppts  
  nS <- max(ppts) # max no of ppts
  bigrams <- bigrams 
  nB <- max(bigrams) # max no of bigrams
  condition <- components 
  K <- max(components) # no of conditions
  y <- data$IKI
  N <- nrow(data)
} )
```

The information in the data list can be viewed using the `glimpse` function.

```{r}
glimpse(data_list)
```


## Load model

The Stan code described in the manuscript was extended to fit more than one copy-task component (or generally condition) at once. The code is saved in the file "MoG.stan" and can be loaded for data fitting using the `stan_model` function and assign it to the object `mog`. The code needs to available in the current working directory of R.


```{r eval = F}
mog <- stan_model(file = "MoG.stan")
```


This code fits the posterior of a categorical predictor with any number of levels. In other words, the posterior can be used to calculate simple effects, main effects and interactions of a factorial design. We will show below how to calculate a simple effect. The same logic can be used to calculate main effects and interactions. Also, participant estimates are calculated for both mixture components and the mixing proportions by condition. For including more predictors, or removing, e.g., random error terms, or adjusting priors, the user will have to work directly in the Stan code.

This Stan code used is largely based on @sorensen2016bayesian and @vasishth2017. @sorensen2016bayesian presents a detailed tutorial on how to fit Stan models [see also @lambert2018student].



## Initiate sampling

For the model to converge we need to run a sufficient number of iterations. 30,000 iterations, as below, are a lot but does not guarantee convergence. We need to test convergence using the model's posterior (see blow). To test whether the model has converged, we need to run the model more than one time (i.e. different chains). These can be run at the same time (in parallel) using more than one core of your computer (three cores below).^[If you want to use R to check how many cores are available on your machine, run `parallel::detectCores()` (you might need to install the package `parallel`).] There is no need to use more cores and chains and using less cores would mean that at least one process has to wait until after other processes are completed. When the model has settled on a parameter values, we should observe that all three streams (chains) overlap. Running long chains (many iterations) is useful to get more accurate parameter estimates. 


```{r}
iterations <- 30000       # Number of iterations
warmup <- 15000           # Warmup samples to be discarded
n_chains <- n_cores <- 3  # Number of chains and cores used (one chain per core)
```


The model is fitting a number of parameters that are not relevant for our inference. To reduce the size of the posterior we can select the parameters of interest. 

```{r}
# Parameters to keep in output
pars <- c("beta",                        # fluent typing
          "delta",                       # disfluency slowdown
          "theta",                       # mixing proportion
          "beta_s",                      # by-participant typing speed
          "theta_s",                     # by-participant disfluency probability
          "sigma",                       # variance component
          "sigma_diff", "sigmap_e", "sigma_e",  # variance by mixture component
          "sigma_u", "sigma_w",          # variance for random ppt and bigram intercepts
          "log_lik",                     # log likelihood (for model comparison) 
          "y_tilde")                     # predicted data 
```


The `sampling` function applies the model to the data using the information specified above (iterations, warmup, chains, cores, parameters `pars` to be saved). `save_warmup` is set to `FALSE` to discard the warmup samples (which are not used for inference anyway) to reduce the size of the posterior. To allow reproducibility (and be cause Bayesian models involves random number generation) we set the seed. The seed can be any number but using the same number ensures the use of the same random number. Lastly, the control argument was specified with higher values for `adapt_delta` and `max_treedepth`: using higher values here mean the model runs slower but supports more careful parameter estimation. The model is assigned to the variable `m`.

```{r eval = F}
# Fit model
m <- sampling(mog, 
              data = data_list,
              iter = iterations,
              warmup = warmup,
              chains = n_chains, 
              cores = n_cores,
              pars = pars, # Parameters to keep.
              save_warmup = FALSE, # Don't save the warmup samples.
              seed = 365, 
              control = list(adapt_delta = .96, # default: .9
                             max_treedepth = 12)) # default: 10
```

Running this model will take a while to complete sampling depending on your hardware specifications. The time it took my machine to complete this job can me viewed using `get_elapsed_time`. Therefore it is worth to not use all cores for this to run or to use a dedicated high performance machine.


```{r echo = F}
m <- readRDS("MoG.rda")
```


```{r}
get_elapsed_time(m)/60 # in mins
```


## Reusing model output

The output of the model (i.e. the posterior) can be saved, so we don't need to run the model again (which admittedly can take a while). The function requires the name of the fitted model `m`. We prefer to keep the name of the output similar to the name of the Stan code used. The model is stored as compressed .rda file.

```{r eval = F}
saveRDS(m, "MoG.rda", compress = "xz")
```

The model can be load into the environment of R using `readRDS`.

```{r eval = F}
m <- readRDS("MoG.rda")
```



# Model diagnostics

## Convergence

Model convergence can be established in two practically simple techniques. First, we can inspect the chains in trace plots which show the parameter estimate across iterations (here after warmup) for each chain. We will look at the population-level parameters (names are determined by the model) corresponding to the Greek symbols used in the manuscript and assign those to `pars`.

```{r}
pars <- c("beta", "delta", "theta", "sigma", "sigmap_e", "sigma_e")
```

To create trace plots, we can apply the `stan_trace` function to the model `m` and extract the MCMC chains for the parameters in `pars`. The `alpha` argument makes the colours slighly more transparent. If the chains overlap and look like "fat hairy caterpillars", chains have converged on the same target distribution. 

```{r}
# Check convergence
stan_trace(m, pars = pars, alpha = .5)
```



Second, we can calculate the $\hat{R}$ statistic. Successful convergence is reflected in $\hat{R}$ values smaller than 1.05 [@gelman1992]. $\hat{R}$ is similar to the F statistic: it tells us how much bigger the variability between chains is compared to the variability within chains. A value of $\approx 1$ indicates that the variability is essentially identical signifying convergence. For this we can use the `rhat` function applied to the model and the population parameters. 

```{r}
summary(m, pars=pars)$summary %>%
  as.data.frame() %>% rownames_to_column("parameter") %>%
  as.tibble() %>% select(parameter, Rhat)
```


Convergence problems can have many reasons and therefore many solutions: running longer chains (in particular longer warmups), increasing the maximum treedepth and the average acceptance probability (`adapt_delta`), specifying starting values, adjusting priors, constraining parameters, or changing the parametrisation of the model. Severe convergence problems are indicative of a misspecification of the model.


## Posterior predictive check

The model used the posterior parameter values to simulate hypothetical data sets. This happened for every iteration for every chains. We can draw predicted data from the model output and compare these to the observed data. A model that makes reasonable predictions should fit the observed data.

```{r echo = F}
(total_samples <- (iterations - warmup) * n_chains)
```


Using the `as.matrix` function we extract a matrix of `y_tilde`, the simulated data. This returns a mtrix with the size `total_samples` $\times$ `nrow(data)` (so `r total_samples` $\times$ `r nrow(data)`). We use the `sample` function to draw `N` randomly sampled hypothetical data sets. The `ppc_dens_oberlay` function from the `bayesplot` package is then mapping the observed data (thick blue line) to the simulated data (thin lightblue lines).

```{r}
y_tilde <- as.matrix(m, pars = "y_tilde")          # extract simulated data sets
N <- 50                                            # number of simulations to use
total_samples <- (iterations - warmup) * n_chains  # total number of samples
rnd_sims <- sample(total_samples, N)               # created random indices
y_tilde_sample <- y_tilde[rnd_sims,]               # draw N simulations at random
```

```{r}
library(bayesplot)
ppc_dens_overlay(data_list$y, y_tilde_sample) +
  scale_x_continuous(limits = c(0, 3000))
```


```{r echo =F}
#sampler_params <- get_sampler_params(m, inc_warmup = FALSE)
#sampler_params_chain1 <- sampler_params[[3]]#colnames(sampler_params_chain1)
#sapply(sampler_params, function(x) mean(x[, "accept_stat__"]))
#sapply(sampler_params, function(x) max(x[, "treedepth__"]))
#inits <- get_inits(m)
#inits_chain1 <- inits[[1]]
#print(inits_chain1)
```


# Posterior probability distribution


At the core of Bayesian inference is the posterior probability distribution. For each model parameter we have `r total_samples` posterior samples that form a posterior probability distribution. This distribution represents the uncertainty about parameter values given the data. There is a large range of things one can do with a posterior. Below we will focus on summarising parameter estimates, comparing conditions, and extracting by-participant estimates.

The `names` function can be used to remind us of the parameter names used in the model (we reduced the output to the first 15 parameter names). The meaning of the parameters is described in the manuscript and can be obtained from the Stan code. Indices refer to the copy-task component (1 = consonants; 2 = LF bigrams) and to the participant identifier for by-participant parameters (indicated with `_s`).


```{r}
names(m)[1:15] 
```


## Parameter-value estimates


```{r}
stan_hist(m, pars = pars)
```


The posterior samples of the parameter values can be summaried using the `print` function. The `probs` argument requires the lower and upper bound of the probability interval that we are interested in. A lower bound of .025 and an upper bound of .975 gives the 95% probability interval (PI), i.e. the range that contains the true parameter value with a 95% probability given the data. 

The output summaries the most probable parameter value as mean with its standard error (`se_mean`) and standard deviation (`sd`), the effective sample size (`n_eff`) indicating sampling efficiency and the convergence metric $\hat{R}$ (`Rhat`) we introduced above. 

```{r}
print(m, pars = pars, probs = c(.025,.975))
```


For the following steps, we will focus on the three parameters that have conceptually interesting interpretations: (1) the average fluent typing speed $\beta$, (2) the disfluency slowdown $\delta$, and the disfluency probability $\theta$.

```{r}
pars <- c("beta", "delta", "theta")
```

The `plot` function shows the posterior probability distribution of the three parameters for the consonants task (indicated as 1) and the LF-bigrams task (indicated as 2) summarised as median and 95% PI.

```{r}
plot(m, pars = pars, ci_level = .95) # ci = credible interval
```

The values for $\beta$ and $\delta$ are shown on a log-scale. To transform their values back to msecs we can extract the posterior samples using the `as.data.frame` function. We prefer the use of tibble objects. 

```{r}
posterior <- as.data.frame(m, pars) %>% as_tibble() 
posterior
```

The `pivot_longer` function is transforming the data above to a long format with an additional column for component and the model parameters kept as columns. The `names_pattern` argument is using a regular expression to extract the number in the squared brackets.

```{r}
posterior_long <- pivot_longer(posterior, everything(), 
             names_to = c(".value", "component"), 
             names_pattern = "(.*)\\[(.)\\]") 

posterior_long
```

This code is then transforming `beta` and `delta` to msecs using the exponential function `exp` to un-log the values. In order to transform the slowdown `delta` into msecs we need to add `beta` before using the exponential function; we can then subtract beta again. The `recode` function changes the component indices from 1 to "consonants" and 2 to "LF".

```{r}
posterior_in_msecs <- mutate(posterior_long,
                             delta = exp(beta + delta) - exp(beta),
                             beta = exp(beta),
                             component = recode(component, `1` = "consonants",
                                                           `2` = "LF"))
posterior_in_msecs
```


The posterior distribution of the parameter estimates can then be visualised in, for example, histograms.

```{r}
posterior_in_msecs %>% pivot_longer(beta:theta, names_to = "parameter") %>%
  ggplot(aes(x = value, colour = component, fill = component)) +
  geom_histogram(position = "identity", alpha = .25) +
  facet_wrap(~parameter, scales = "free", labeller = label_parsed) +
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2")
```



## Difference between components 

We can calculate the differences between the copy-task components for each parameter value. This is giving an indication of whether fluent typing ($\beta$) is influenced by the copy task, maybe the size of the disfluency slowdown ($\delta$) is impacted by the task, or the disfluency probability ($\theta$). 

To determine these differences we change the data format above and create a variable that indicates the parameter and one column for the corresponding values for each copy-task component. The last line calculates the difference between the consonants task and the LF-bigrams task for each of the three parameter values.

```{r}
posterior_by_component <- posterior_in_msecs %>%
  pivot_longer(beta:theta, names_to = "parameter") %>%
  group_by(component) %>%
  mutate(id = row_number()) %>%
  pivot_wider(names_from = component, values_from = value) %>%
  select(-id) %>% # drop id column
  mutate(diff = consonants - LF) # calculate the difference between copy-task components

posterior_by_component
```

The difference between the conditions can be summarised using the mean, the 95% PIs and the probability that the difference between the components is small 0 (indicated as e.g. $P(\hat{\beta} <0)$; the hat symbol indicates population estimate). This summary tells us whether the difference between the consonants task and the LF-bigrams task is different from zero and, indeed, what the most probable value for the difference between tasks is.

```{r}
posterior_by_component %>%
  group_by(parameter) %>%
  summarise(mean = mean(diff),
            lower = quantile(diff, .025),
            upper = quantile(diff, .975),
            p = mean(diff < 0)) %>% 
  mutate(across(where(is.numeric), round, 2))
```

These differences can be viewed in histograms. Interestingly we observe no difference for fluent keystroke transitions. Instead the difference comes from hesitant keystroke transitions; these hesitations are longer and more likely to be observed in the consonants task than in the LF-bigrams task.

```{r}
ggplot(posterior_by_component, aes(x = diff)) +
  geom_vline(xintercept = 0, colour = "grey30", linetype = "dotted") +
  geom_histogram(alpha = .75) +
  facet_wrap(~parameter, scales = "free", labeller = label_parsed) 
```



The Stan code can be used to estimate the posterior for two and more conditions: We can calculate the difference between conditions from the posterior as well as main effects and interactions for more complex factorial designs as any factorial design can be reduced to a single variable.^[For example, say we have a 2 $\times$ 2 factorial design with factor 1 having two levels AB and CD and factor 2 having the corresponding levels AC and BD. These two factors render four conditions A, B, C, D. From posterior samples for each level A through D we can calculate main effect 1 as $\text{ME1}=(A+B) - (C+D)$, main effect 2 as $\text{ME2}=(A+C) - (B+D)$, and their interaction as $\text{Interaction}=(A-B) - (C-D)$ (or $\text{Interaction}=(A-C) - (B-D)$) and summary statistics as shown above.]





## By-participant estimates 

In some contexts we would like to obtain by-participant estimates of the average fluent typing-speed of a participant after accounting for disfluencies (i.e. $\beta_s$); by-participant disfluency information can be estimated the proportion of disfluencies (i.e. $\theta_s$). These estimates inform us about the fluent typing speed but also about the prevalence of typing hesitations.

As before we can extract the posterior from the model `m`. This time we use the parameters that stored by-participant estimates `beta_s` and `theta_s` corresponding to the population estimates `beta` and `theta`. 

```{r}
pars <- c("beta_s", "theta_s")
posterior_ppts <- as.data.frame(m, pars = pars) %>% as_tibble()
names(posterior_ppts)[1:10]
```

This posterior tibble has the format "<parameter name>_s[<component id>, <participant id>]" where indices indicate the copy-task component and the participant identifier of the parameters. The following code is converting the `beta`s to msecs, creates a long format with columns `parameter` with the names above as levels and a `value` column with their respective values. The `parameter` column is then separated into `parameter` (`beta`, `theta`), `component` (`1`, `2`), and participant (an index for each participant) using "," to separate the three variables. To use "," as separator we replace "_s" with "," in the line before. Copy-task component names were changed as before. A preview is below.


```{r}
posterior_ppts_long <- posterior_ppts %>%
  # use exp() on everything starting with "beta"
  mutate(across(starts_with("beta"), exp)) %>%             
  pivot_longer(everything(), names_to = "parameter") %>%
  # replace "_s" with "," 
  mutate(parameter = gsub("_s", ",", parameter)) %>%
  # separate into parameter, component, ppt using "," as separator
  separate(parameter, into = c("parameter", "component", "participant")) %>% 
  mutate(component = recode(component, `1` = "consonants", `2` = "LF")) %>%
  group_by(parameter) %>% mutate(id = row_number()) %>%
  pivot_wider(names_from = parameter, values_from = value) %>% select(-id)

posterior_ppts_long
```

We can then summarise by-participant estimates for each component and parameter with the most probable parameter value and the 95% PI as before.

```{r}
posterior_ppts_long_summary <- posterior_ppts_long %>%
  pivot_longer(beta:theta, names_to = "parameter", values_to = "value") %>%
  group_by(parameter, component, participant) %>%
  summarise(mean = mean(value),
            lower = quantile(value, .025),
            upper = quantile(value, .975))

posterior_ppts_long_summary
```


These estimates look like this:


```{r}
ggplot(posterior_ppts_long_summary, aes(x = as.numeric(participant),  
                                        y = mean, ymin = lower, ymax = upper,
                                        colour = component)) +
  geom_pointrange(position = position_dodge(.75)) +
  facet_wrap(~parameter, scales = "free", labeller = label_parsed) +
  coord_flip() +
  labs(y = "Participant id", x = "Parameter estimates") +
  scale_colour_brewer(palette = "Dark2")
```






# References

<div id="refs"></div>

