---
title             : "Modelling typing disfluencies using Bayesian mixture models"
shorttitle        : "Modelling typing disfluencies"

csl               : "apa.csl" 

author: 
  - name          : "Jens Roeser"
    affiliation   : "1"
    address       : "50 Shakespeare St, Nottingham NG1 4FQ"
    corresponding : yes 
    email         : "jens.roeser@ntu.ac.uk"
  - name          : "Sven De Maeyer"
    affiliation   : "2"
  - name          : "MariÃ«lle Leijten"
    affiliation   : "3"
  - name          : "Luuk Van Waes"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Nottingham Trent University, United Kingdom"

  - id            : "2"
    institution   : "Faculty of Social Sciences, University of Antwerp, Belgium"

  - id            : "3"
    institution   : "Department of Management, University of Antwerp, Belgium"


abstract: |
   The analysis of keystroke-latency data typically involves the calculation of summary statistics such as the mean inter-keystroke interval and pause frequencies. There are two fundamental problems with this: first, summary statistics ignore important information in the data and frequently result in biased estimates; second, pauses and pause-related measures are defined using threshold values which are, in principle, arbitrary. We implemented a series of Bayesian models that aimed to address both issues by providing reliable estimates for individual typing speed and statistically inferred process disfluencies. We tested these models on a random sample of 250 copy-task recordings. Our results illustrate that we can model the copy typing as a mixture process of normal typing and typing disfluencies. We conclude that mixture models (1) map onto the information cascade that generate keystrokes, and (2) provide a principled approach to detect disfluencies in keyboard-typing data.


keywords: "Copy-task; keystroke modelling; autoregression; mixture models; Bayesian statistical models; typing skills"


bibliography      : ["ref.bib"]


documentclass     : "apa7"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: TRUE
#  papaja::apa6_docx:
#    keep_tex: TRUE
#    reference_docx: xxx.docx



figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : yes
csquotes          : true


header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{graphicx}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{threeparttable}
  - \usepackage[normalem]{ulem}
  - \usepackage[utf8]{inputenc}
  - \usepackage{icomma}
  - \usepackage{pdflscape}
  - \newcommand{\blandscape}{\begin{landscape}}
  - \newcommand{\elandscape}{\end{landscape}}
---

```{r setup, include=FALSE}
library(magrittr)
library(tidyverse)

library(papaja)
library(knitr)
library(citr)
library(kableExtra)

library(tidybayes)
library(grid)
library(gridExtra)
library(ggstance)
library(ggforce)
library(ggthemes)
library(ggExtra)
library(cowplot)

source("../functions/functions.R")
source("../functions/get_data.R")

knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      cache.extra = R.version,
                      dev = "cairo_pdf"
                      )
options(kableExtra.auto_format = FALSE)
dev.args = list(pdf = list(type = "cairo"))

theme_set(theme_few(base_size = 9) + theme(axis.ticks = element_blank(),
                                           legend.position = "top",
                                           legend.justification = "right"))

mycolours = c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

Ms <- c("Median" = "dotted", "Mean" = "longdash", "Mode" = "solid")
Mcol <- c("Median" = "darkolivegreen4", "Mean" = "turquoise4", "Mode" = "darkred")

posn.j <- position_dodge(width = 1)
label = "Copy-task\ncomponent: "

# Load df
path <- "../data/"
#d <- get_data(path = path) %>% filter(component == "Consonants") %>% select(-component)
d <- get_data(path = path) %>% filter(component %in% c("Consonants", "LF"), rep == 1) %>%
  select(subj, bg, bigram, IKI, sex, age, component)

d_sample <- d %>% select(ppts = subj, bigram = bg, IKI, component)
write_csv(d_sample, "../data/used_sample.csv")
```




# Introduction

**Hesitations in keyboard typing are indicative of processes on higher levels of cognitive activation. For example, when being asked to copy the word "piobaireachd", you might pause mid-word to remind yourself of the spelling or double-check the spelling of the word you began writing against the target word. The maximum fluency when copying or indeed composing text is restricted by how fast we can move our fingers -- plan and execute motor codes. However, sometimes upstream processes have to catch up -- when double-checking the target word's spelling or when deciding what to say next -- meaning that the output speed decreases. These hesitations are typically referred to as disfluencies and are invaluable to develop a theoretical understanding of an individual's writing dynamics.**


**Whether or not or how often we hesitate when copying a word gives insight into our ability to translate visual input into motor plans (and execute these). In spontaneous production disfluencies allow insight into the information cascade that underlies language production from the mental generation of a message, into grammatical processing, and finally the generation and execution of motor codes. In particular disfluencies are indicators of process demands that arise on higher levels of mental representation [@christiansen2016now; @olive2014toward]; for example when preplanning syntactic dependencies [@roeser2019advance] or retrieving the lexical entry of a word or its spelling [@torrance2016adolescent]. This idea can be found in theoretical models of spoken language production [@bock2014syntactically], handwriting [@van1991handwriting] and keyboard typing [@hayes2012evidence]. Copy-typing, in contrast to free text production, does not require the generation and linguistic translation of contents but allows us to restrict the typing process to activity on motor level [@leijten2013keystroke; @van2019multilingual; @waes2019]. Hesitations, however, arise during both copy-typing and unconstrained text production. Consequently, data from keyboard typing involves a combination of, at least, two processes that arise from (1) a smooth information flow from higher to lower levels of activation -- maximum fluent motor execution -- and (2) hesitations at the execution stage resulting from inhibitions on higher levels of activation -- output disfluencies. At present there is no principled way to detect keystroke intervals that can be considered disfluencies. In this paper we present a series of statistical models that aim to capture this theoretical process underlying keyboard typing as a combination of fluent and disfluent keystroke transitions.**



Writing research has made extensive use of keystroke-logging to inform the process underlying keyboard typing. Keystroke logs provide rich information about the typing process. From these logs, researchers can calculate different process measures including measures of writing fluency [@chukharev2019combined; @van2015fluency; @medimorec2016effects; @medimorec2017disfluency]. To name a few, researchers have performed data analysis on means, medians and standard deviations of inter-keystroke intervals (the latency between two consecutive keystrokes), number of pauses or pause duration and within-word keystroke intervals [for an overview of frequently used keystroke measures see @conijn2019understanding]. @conijn2019understanding suggested that these aggregates are sensitive to processing difficulty that arises on different levels of mental representation. However, there are two substantial problems tight to the use of summary statistics to develop an understanding of the typing process. 

First, pause frequencies, writing bursts and related measures are used to assess writing performance [e.g. @alves2015progress; @beers2017effects; @zhang2019there]. These measures require a definition of what passes as a pause [@wen06;@van2016keystroke], i.e. a pause criterion threshold often set to 2 secs [@chanquoy1996writing; @kaufer1986composing; @sullivan2002self;@wen02] or some other lower bounds [@chukharev2014pauses; @connelly2012predicting; @leijten2013keystroke]. Researchers have stipulated pause thresholds specific to their research purposes and based on prior research. However, ideally, this threshold would need to be specific to factors such as location in the text, writing task and the skills of the typist [@wen06]. This is because, for example, pauses long values are less unusual for before sentences than within words. Also, when comparing the frequency of pauses larger than 2 secs for dyslexic and normal typists, one might observe more pauses for dyslexic individuals merely because writing execution unfolds generally more slowly than for proficient typists; indeed pauses shorter than 2 secs for proficient typists would be neglected entirely [@wengelin2001disfluencies]. In other words, a difference in typing-execution speed would give the illusion of a larger number of pauses if dyslexic typists. The same applies to the interpretation of pausing in L2 typists and the use of other threshold criteria [@van2015fluency]. 


Second, data aggregation results in the loss of important information about disfluencies and time course variation. Even if this variation is not of interest to a research question, parametric aggregates such as mean and standard deviation, and even non-parametric descriptives such as median and interquartile range, are biased estimates for keystroke data. **This is because summary statistics capture some aspects of the data but neglect others. For example, both mean and median represent the centre of a normal distribution. For non-normally distributed data, the mean represents the average -- extreme values pull the mean away from the center of the distribution -- but does not capture where the majority of the data lies; the latter is captured by the median.** This is a problem for keystroke data. People tend to aim for high typing speed with a lower bound that is restricted by the time it takes to plan and execute motor programs.^[Plus keyboard polling.] Yet, writers can slow down typing execution and pause as long as they wish; hence keystroke intervals have, in principle, no upper bound. The combination of these two factors renders a distribution that has a strong positive skew. Figure \ref{fig:example} illustrates the mismatch between observed data and the normal distribution implies by parametric summary statistics. The figure shows a sample taken from the copy-task log of two participants (from the copy-task data reported below). For the keystroke intervals of either participant, we contrast the density function of the empirical data (dashed line) and the normal density function (solid line). The normal density function is based on the observed mean (dotted vertical line) and standard deviation (see figure caption). Panel A shows the untransformed inter-keystroke intervals; Panel B shows the log-transformed data.


```{r example, fig.pos="bp!", fig.height = 4.5, fig.width = 6.5, fig.align = "center", fig.cap="Example for mean as biased estimator for the inter-keystroke intervals (IKIs) for two participants (participant 72 in the top panels; participant 75 in the bottom panels). All panels show the empirical density of the data and the normal-density function entailed by the observed mean (represented as dotted vertical line) and the standard deviation (SD): participant 72: mean=431 (SD=448), participant 75: mean=256 (SD=98). The untransformed IKIs are shown in plot A and the log-scaled IKIs are shown in plot B."}
source("scripts/get_example_plot.R");plot
#filter(d_summary, subj == unique(d_summary$subj)[1]) %>% pull(mean)
#filter(d_summary, subj == unique(d_summary$subj)[1]) %>% pull(sd)
#filter(d_summary, subj == unique(d_summary$subj)[2]) %>% pull(mean)
#filter(d_summary, subj == unique(d_summary$subj)[2]) %>% pull(sd)
```

Figure \ref{fig:example} shows a poor match between the parametric summary measures of both the untransformed and the log-scaled keystroke data of participants 72 and 75 and the normal distribution entailed by the observed mean and standard deviation. Importantly, this mismatch is not only due to the positive skew in the keystroke data but might be related to a bimodal tendency that can be seen best in the log-scaled keystroke-intervals shown in Figure \ref{fig:example}B; the empirical-density function shows two peaks in both participants. This mixture of short and long keystroke intervals is going to influence the reliability of summary statistics.

Therefore, data aggregation may lead to incorrect inference about the writing process [@baaijen2018discovery]. To address biases in these estimates researchers have used data transformation, and data trimming [@hoaglin1987fine] to remove data that were considered outliers, or separated disfluencies (or pauses) from short keystroke transitions. However log-transformation may account for positive skew but does not address the bimodality, as illustrated in Figure \ref{fig:example}B. From existing research we know that keystroke data are not merely positively skewed, which can be addressed with log-normal transformations, but heavily right tailed [@almond2012preliminary; @baaijen2012keystroke; @chukharev2014pauses; @guo2018modeling]. Further, using fixed threshold values to distinguish between normal and delayed typing intervals will inevitably impact more on struggling writers but also learners and and dyslexic individuals more generally) leading to larger data loss, less reliable typing estimates and therefore incorrect conclusions about the hypothesis tested. A pause threshold would need to be participant-specific [@wen06] but is more difficult to determine for individuals with a larger variability (e.g. participant 72 in Figure \ref{fig:example}A).    

A central methodological challenge with implications for writing research [@hayes2012evidence; @kaufer1986composing; @wen06; @van2016keystroke] is the detection of writing disfluencies. We addressed this problem by implementing statistical models that aim to capture the nature of the data generating cognitive process that underlies keyboard typing. Crucially we want a statistical model that provides reliable estimates of typing performance without subjecting the data to trimming or threshold criteria, aggregation or manual manipulation, and also accounts for typing disfluencies and other properties of the data (e.g. individual typing style, key-pair specific differences). **To test the model that we describe in the following section we use data from two copy-tasks. Using a constrained writing context such as a copy task rather than data from spontaneous text production was fundamentally important for our purposes. This is because, first, we can reduce the influence of higher level processes: text production involves the generation of content and its linguistic encoding but copy-typing does not. In other words, the cognitive source of longer keystroke intervals is less ambiguous. Second, spontaneous text production comes with a considerable variability between what participants write. In a copy task we can largely control this variability. Using data from a copy task can therefore, reduce the number of confounding factors.**




# Method

## Modelling the copy-typing process

As a guiding principle, we aim to produce a statistical model that represents the mental process that generates the keystroke data. Keystrokes, in copy-typing and free text production, are the end of a cascade of mental processes. Lags between subsequent keypresses, for example, the transitions c$^{\wedge}$a$^{\wedge}$t for the word _cat_, where $^{\wedge}$ indicates the inter-keystroke intervals (IKI) between pressing $<$c$>$ and $<$a$>$, and $<$a$>$ and $<$t$>$, increase when the information flow into motor execution was interrupted at a higher level. Keystroke intervals reflect at minimum two states of this information flow: (1) either activation can flow into motor plans and keystroke transitions are maximal fluent; (2) activation flow was inhibited at a higher level and therefore the time between two keystrokes increased. 

For example, writing a word involves the retrieval of its name and, then, its spelling. If the writer knows both, activation can flow smoothly into the execution of the corresponding motor codes. However if the writer struggles to retrieve the spelling for or the lexical entry of a word, the activation flow is being interrupted. Inhibition is then resulting in process disfluencies expressed in a larger lag between adjacent keys. In copy-typing tasks we can constrain the underlying cognitive process by removing higher-level processes such as lexical planning and orthographic retrieval [@grabowski2008internal;@wallot2013typewriting]. Figure \ref{fig:model} illustrates a basic model of the copy-typing process [see also @yamaguchi2014pushing; @logan2011hierarchical; @salthouse1984effects]. At the top level, some chunk of letters has to be visually encoded. The size of this chunk is to some extent specific to task, target string, individual typing skill / style, but mainly constrained the verbal working memory of the participant. The visually encoded sequence has to be buffered and, then, corresponding motor codes have to be activated. If there are no more motor codes that can be generated from the buffered information, visual encoding is required to update the buffer.


```{r model, fig.pos="bp!", fig.height = 3.5, fig.width = 6.5, fig.align = "center", fig.cap="Basic model of copy typing; example for ``een chaotische cowboy'' (a chaotic cowboy)."}
include_graphics("spelling_decision.pdf")
```

The consequence of buffer updates is a slowdown in keystroke intervals (i.e. a pause, disfluency) that cannot be explained on the basis of lexical retrieval or difficulty with particular bigrams. Figure \ref{fig:example2} shows the by-bigram IKIs of three participants copy-typing the (Dutch equivalent of the) phrase *a chaotic cowboy*. These example data illustrate that disfluencies are not bigram-related difficulty. Participant 241 shows a longer IKI for $<$c$>$ and $<$h$>$ but no other notable slowdown; participant 105 shows a large IKI for $<$o$>$ and $<$t$>$; participant 232 shows two, a smaller and a larger peak in IKIs. Importantly, although to-be-copied words were the same, the number, location, and size of the slowdown varied across participants. The model in Figure \ref{fig:model} captures these disfluencies as buffer updates. Our statistical model should provide a systematic way of addressing process disfluencies, even though their occurrence is, to some extent, non-deterministic -- disfluent keystroke transitions within a sequence of letters (i.e. between spaces) cannot be predicted on the basis of letter identity or bigram location.


```{r example2, fig.pos="bp!", fig.height = 3.5, fig.width = 6.5, fig.align = "center", fig.cap="Example of the inter-keystroke intervals (IKIs) from three participants, shown as different linetypes, copy-typing ``een chaotische cowboy'' (a chaotic cowboy)."}
lf <- c("een", "chaotische", "cowboy")
lf_bgs <- c("ee", "en", 
            "ch", "ha", "ao", "ot", "ti", "is", "sc", "ch", "he", 
            "co", "ow", "wb", "bo", "oy")#;length(lf_bgs)

d_example2 <- d %>% filter(component == "LF") %>% 
  mutate(subj = as.character(subj)) %>%
  group_by(bg) %>%
  mutate(n = length(bg)) %>% filter(n > 2, bg %in% lf_bgs) %>%
  group_by(subj) %>%
  mutate(bigram = 1:n(),
         n2 = n()) %>%
  filter(n2 == 16)

#d_example2 %>% pull(subj) %>% unique()
#d_example2 %>% pull(bg) # %>% unique()

d_example3 <- d_example2 %>% filter(subj %in% c(105, 241, 232))

ggplot(d_example3, aes(y = IKI, x = bigram, linetype = subj, group = subj, shape = subj)) +
  geom_point(position = position_dodge(.5), size = 2) +
  geom_line(position = position_dodge(.5)) +
  labs(shape = "Participant id:", linetype = "Participant id:",
       y = "IKIs [in msecs]", x = "Bigrams") +
  scale_shape_manual(values = 21:23) +
  scale_x_continuous(breaks = sort(unique(d_example3[d_example3$ subj == unique(d_example3$subj)[1],]$bigram)), 
                     labels = d_example3[d_example3$subj == unique(d_example3$subj)[1],]$bg) +
  theme(legend.key.width =  unit(1, "cm"))
```



Statistical models can be used to characterize the theoretically assumed data-generating process as a function of parameters. For example, if we assume that the data com from a single underlying process, we can describe this process with a normal distribution that takes two parameters, the mean $\mu$ and the variance $\sigma^2$. The values of the parameters $\mu$ and $\sigma^2$ are unknown and typically used to represent and compare task and population specific (typing) performance. This model can be written as $y \sim Normal(\mu, \sigma^2)$; i.e. the data $y$ come from a single process that follows a normal distribution with an unknown mean $\mu$ and an error variance $\sigma^2$. We can then feed data to our statistical model to estimate values for the model parameters. The resulting parameter estimates can then be interpreted in the realm of the assumed data-generating (cognitive) process; i.e. a single process that generates normal distributed data.


### Log-normal mixed-effects model of typing 


For the first model, the baseline model, we will assume that IKIs follow a log-normal distribution [e.g. @almond2012preliminary;@guo2018modeling] because IKIs are zero-bound and therefore positively skewed [@baa08book].^[We discussed above that the heavy tail associated with keystroke data is not necessarily fitting a log-normal distribution. We used this model as it is roughly equivalent to the standard statistical method used in the field (e.g. fitting parametric models to log-transformed data).] This model is characterising the information cascade that generates keystroke intervals with the population mean-keystroke transition.

To estimate the mean we need to be able to account for variability related to the sampling process. This can be achieved with log-normal (linear) mixed-effects models (LMM) which have been used in the literature to model keystroke data [@leijten2011coordinating;@quene2004multi; @waes2019; @van2010reading]. The LMM in equation \ref{eq:lmm} is an extension of the simple example above. We know that some participants are faster typists than other participants and some bigrams are faster to type than others. Writers vary generally in how fast they type, or how quickly they are performing in the given task. Further, more frequent bigrams (as part of words with a large number of occurrences in a corpus or bigrams that occur in many different words) are typically typed faster than low frequency bigrams; bigrams that are part of words are typed faster than novel bigrams; bigrams within morphological boundaries are typed faster than bigrams that cross morphological boundaries with similar effects for syllable boundaries [@feldman2019lexical; @pinet2016typing; @not05; @sah08; @gen88; @wei04]. 


In other words, IKIs for participants and bigrams are varying around a common mean. These sources of random-error variance are captured by $u$ for participants and $w$ for keystroke bigrams in equation \ref{eq:lmm}. The population mean after accounting for variance associated with participants and bigrams is captured by the parameter $\beta$.


\begin{equation}
\begin{aligned}
(\#eq:lmm)
y_{ij} \sim LogNormal(\mu, \sigma_e^2)\\
\mu_{ij} = \beta + u_i + w_j
\end{aligned}
\end{equation}


Each participant $i$ has a difference, expressed as $u_i$, from the population mean $\beta$ that should be close to 0 with some participants being faster than average (i.e. $<0$) and other are being slower than average (i.e. $>0$); these differences can be assumed to be normally distributed with a between-participants variance $\sigma_u^2$ with $i = 1, \dots, I$, where $I$ is the number of participants (see \ref{eq:lmm2}). Because $\sigma_u^2$ is a variance it can not be negative so we can cut off the normal distribution at zero. 


, and choose 2.5 as the variance, because the majority of participants should have, by definition, an average IKI close to zero with fewer participants being much faster or slower than the average. A variance of 2.5 is a reasonably informative prior that ensures that the variability across participants is approximately normal. This type of distribution is known as a half-normal [@gelman2006prior].

\begin{equation}
\begin{aligned}
(\#eq:lmm2)
u_i \sim Normal(0,\sigma_u^2)\\
\sigma_u \sim Normal(0,2.5)\\
\text{constraint: } \sigma_u >0 
\end{aligned}
\end{equation}

Similar to variability between participants we can model variation between keystroke pairs (i.e. letter bigrams) as random-intercepts term; $w$ in equation \ref{eq:lmm} [@van2019multilingual;@waes2019]. More specifically, this is to assume that each bigram $j$ with $j = 1, \dots, J$, where $J$ is the total number of bigrams, is independent of the other bigrams. Each bigram-intercept difference $w_j$ is distributed around 0 with a between-bigram variance $\sigma_w^2$ (equation \ref{eq:lmm5}).


\begin{equation}
\begin{aligned}
(\#eq:lmm5)
w_j \sim Normal(0,\sigma_w^2)\\
\sigma_w \sim Normal(0,2.5)\\
\text{constraint: }\sigma_w >0 
\end{aligned}
\end{equation}

The parameter of interest, the mean $\beta$ in equation \ref{eq:lmm}, is the marginalised value after taking into account random variation between participants and bigrams. In all models we parameterised the mean $\beta$ as non-centered with regulating priors [equation \ref{eq:lmm3}; following @gelman2014;@papaspiliopoulos2007general]. Non-centering parameters can be used to aid sampling efficiency of the model. In other words, a more reliable parameter estimate can be achieved with the same number of iterations. For the mean $\mu_\beta$ of the population mean $\beta$, we proposed a normal distributed prior centered around 5 (i.e. log of $\approx$ 150 msecs).

\begin{equation}
\begin{aligned}
(\#eq:lmm3)
\beta = \mu_{\beta} + \sigma_{\beta} \cdot \epsilon\\
\mu_{\beta} \sim Normal(5,2)\\
\sigma_{\beta} \sim Normal(0,1)\\
\epsilon \sim Normal(0,1)\\
\text{constraint: }\sigma_{\beta}>0 
\end{aligned}
\end{equation}

For the unexplained residual variance $\sigma_e^2$, we used an uninformative half-Cauchy prior [equation \ref{eq:lmm4}; as mentioned in @gelman2014]. The Cauchy is a heavy tailed distribution; a centre of 0 indicates that the residual variance should be close to 0 but the scale 2.5 allows for larger values.

\begin{equation}
\begin{aligned}
(\#eq:lmm4)
\sigma_e \sim Cauchy(0,2.5)\\
\text{constraint: }\sigma_e>0 
\end{aligned}
\end{equation}



### Typing as autoregressive process

The previous model captures variation associated with bigrams but assumes that their locations are independent and thus exchangeable. In other words, keystroke intervals depend on the identity of the associated bigram but not on the duration of a preceding keystroke interval. There is however evidence that keystroke intervals tend to be longer at certain locations such as before phrases [@roeser2019advance] and words [@torrance2016adolescent] than within words; keystroke intervals are longer on syllable and morphological boundaries than within syllables and morphemes, respectively [@not05]. IKIs are not necessarily independent of preceding keystroke intervals; an IKI $y_{i}$ might be related to the IKI $y_{i-1}$ preceding it, for example, such that a disfluency impacts on neighbouring keystroke intervals [@conijn2019typo]. The relationship between subsequent keystrokes can be captured by predicting an IKI with the IKI preceding it. This is called an autoregressive process [@eltahir2004dynamic]; in equation \ref{eq:ark} the relationship between subsequent IKIs is captured by the parameter $\phi$. As the degree of autocorrelation might vary with typing skill, we assumed that the autocorrelation varies between participants $\phi_i$ with a centered mean $\mu_{\phi}$ and error variance $\eta^2$. 


\begin{equation}
\begin{aligned}
(\#eq:ark)
y_{ij} \sim LogNormal(\mu_{ij}, \sigma_e^2)\\
\mu_{ij} = \beta + \phi_i \cdot log(y_{ij-1}) + u_i + w_j\\
\text{where}\\
\phi_i \sim Normal(\mu_{\phi}, \eta^2)\\
\mu_{\phi} \sim Normal(0, 1)\\
\eta \sim Cauchy(0, 1)\\
\text{constraint: }\eta >0 
\end{aligned}
\end{equation}


### Typing as mixture process

So far we constructed models that account for the keystroke-interval differences associated with different typists, bigrams and that accounts for autocorrelation between subsequent keystroke-intervals. Next we will add a modelling component that allows us to distinguish between fluent and disfluent keystroke intervals using what is called a finite mixture-process model. 

Mixture models are a straight-forwarded way of representing a data-generating process that involves a combination of different subprocesses [e.g. @farrell2018computational; @gelman2014]. Finite-mixture models have been used to represent cognitive processes in which larger values arise in a probabilistic manner [see e.g. @vasishth2017; @vasishth2017feature]. Keystroke disfluencies in writing can be represented in a similar way. For keystroke data, the assumed process is a finite mixture (i.e. combination) of two processes representing (1) normal typing, when activation can flow from higher into lower mental levels, and (2) typing disfluencies, when activation flow is interrupted (e.g. for a buffer update). In other words, we fixed the number of underlying distributions to two, namely 2 log-Gaussian (log-normal) distributions, of which one represents fluent typing (shorter IKIs) and the other represents disfluencies (longer IKIs). 

This model can be summarised as in equation \ref{eq:mog}, following @vasishth2017. The first and second line express that the data $y$ are modelled as the sum of two weighted log-normal distributions of which the first distribution has a mixing proportion $\theta$ (weight) and the other distribution receives the remaining proportion $1-\theta$. $\theta$ was used here as the unknown probability of process disfluencies. This was achieved by fixing the mean $\beta$ for both distributions but adding the parameter $\delta$, that was constrained to be positive, to the first distribution. $\delta$ is therefore capturing the latency magnitude of process disfluencies with $\theta$ indicating the probability of disfluencies to occur. The probability of disfluent IKIs was allowed to vary across participants $i$ and stored in $\theta_i$. This is because the probability to exhibit disfluencies can be assumed to depend on individual typing style (and skills).



\begin{equation}
\begin{aligned}
(\#eq:mog)
	y_{ij} \sim \theta_i \cdot LogNormal(\beta + \delta + u_i + w_j, \sigma_{e'}^2) +\\
		(1 - \theta_i) \cdot LogNormal(\beta + u_i + w_j, \sigma_{e}^2)\\
		\text{where}\\
		\delta \sim Normal(0,1)\\
		\text{constraint: } \delta > 0
\end{aligned}	
\end{equation}

To increase sampling efficiency we placed a continuous prior on the logit of the individual mixing proportions $\alpha_i$, which was transformed to range between 0 and 1, using the inverse-logit function, and stored in $\theta_i$. This is shown in equation \ref{eq:mog2}. We used a normal prior for the logit of individual mixing proportions $\alpha_i$ with a mean $\mu_{\alpha}$ that captures the logit of the population disfluency-probability (with an error variance $\tau^2$). The hyper-prior on the population mixing-proportion $\mu_{\alpha}$ was assumed to have a mean of logit 0, corresponding to a probability of 0.5 and a variance of logit 1 (i.e. $\approx$ 0.73 in proportions).


\begin{equation}
\begin{aligned}
(\#eq:mog2)
		\theta_i = Logit^{-1}(\alpha_i)\\
		\alpha_i \sim Normal(\mu_{\alpha},\tau^2)\\
		\mu_{\alpha} \sim Normal(0,1)\\
		\tau \sim Cauchy(0,1)\\
		\text{constraint: } \tau > 0
\end{aligned}	
\end{equation}


As longer latencies are known to be associated with a larger variances for both response-time data in particular [@wagenmakers2007linear] and human motor behaviour in general [@wing1973response;@schoner2002timing], we constrained the variance $\sigma_{e'}^2$ associated with the distribution of typing disfluencies to be larger than the variance for normal typing $\sigma_e^2$; see equation \ref{eq:mog3} [see @vasishth2017; @vasishth2017feature].

\begin{equation}
\begin{aligned}
(\#eq:mog3)
		\sigma_{e'} = \sigma + \sigma_{\text{diff}}\\
		\sigma_{e} = \sigma - \sigma_{\text{diff}}\\
		\sigma_{\text{diff}} \sim Normal(0,1)\\
		\sigma \sim Cauchy(0,2.5)\\
		\text{constraint: } \sigma, \sigma_{\text{diff}}, \sigma_{e'}, \sigma_{e} > 0
\end{aligned}	
\end{equation}


### Typing as autoregressive mixture process

The mixture model, as well as the LMM, assumes that lags between subsequent letter bigrams are independent of each other; the argument against this was introduced above for autoregressive models. We implemented another mixture model that is largely equivalent to the model presented in the previous section but includes an autoregressor as in equation \ref{eq:ark}; see equation \ref{eq:mogark} for the autoregressive mixture-process model.

\begin{equation}
\begin{aligned}
(\#eq:mogark)
	y_{ij} \sim \theta_i \cdot LogNormal(\beta + \delta + \phi_i \cdot log(y_{ij-1}) + u_i + w_j, \sigma_{e'}^2) +\\
		(1 - \theta_i) \cdot LogNormal(\beta + \phi_i \cdot log(y_{ij-1}) + u_i + w_j, \sigma_{e}^2)\\
\end{aligned}	
\end{equation}


```{r }
d.ppt <- d %>% select(subj, age, sex) %>% unique()
d.sex <- d.ppt %>% count(sex) %>% pull(n) # femanle, male
d.age <- d.ppt %>% summarise(M = median(age), min = min(age), max = max(age)) %>% 
  gather(p, value) %>% pull(value) %>% round(0) 
```



## Copy-task data

To test which model captures the typing process best, we applied the four models described in the previous section to data from a subset of the Dutch copy-task corpus [@leijten2013keystroke; @waes2019; @van2019multilingual]. An overview of all models can be found in Table \ref{tab:models}.


```{r models, results = 'asis'}
models <- tibble(Models = paste0("M",1:4),
       Type = c("LMM", "AR", "MoG", "AR + MoG"),
       Equation = paste0("\ \\ref{eq:", c("lmm", "ark", "mog", "mogark"), "}"),
       Description = c("Baseline model",
                       "Autocorrelation between subsequent IKIs",
                       "Mixture process of fluent and disfluent typing",
                       "As M3 but with autocorrelation component")) 

papaja::apa_table(models, align = c("l", "l", "l"), escape = FALSE, digits = 0, placement = "bp!",
                  caption = "Overview of typing-process models. All models were fitted with random intercepts for participants and bigrams.",
                  note = "LMM = Linear mixed-effects models; AR = Autoregressive model; MoG = Mixture of log-Gaussians") 
```


The copy-task corpus consists of keystroke data collected via Inputlog, a Javascript-based web application available on \url{www.inputlog.net} with the source code released on [github.com/lvanwaes/Inputlog-Copy-Task](https://github.com/lvanwaes/Inputlog-Copy-Task) and [zenodo.org/record/2908966](https://zenodo.org/record/2908966). In a set of different subtasks participants had to produce keyboard-typed responses. We used a random sample of `r nrow(d.ppt)` participants (`r d.sex[1]` females, `r d.sex[2]` males, `r d.sex[3]` unknown) from the age range of `r d.age[2]` to `r d.age[3]` years (median age = `r d.age[1]` years). Before analysis we excluded spaces and editing operations from the data. 

In this analysis we focus on the consonants task and the low-frequency (LF) bigrams task. In the consonants task, participants saw and copy-typed a single time four blocks of six consonants; i.e. "tjxgfl pgkfkq dtdrgt npwdvf". This task is intended to measure typing skills in a non-lexical environment [@grabowski2010second]. We repeated the analysis for the LF-bigrams task to contrast the non-lexical consonants task and a lexical copy task. In the LF-bigram task, participants typed three-word combinations seven times (*een chaotische cowboy* 'a chaotic cowboy' in the Dutch version) of which four bigrams are low frequent.^[Note, we refer to this task as *LF*-bigrams task as in @van2019multilingual. The majority of bigrams in the target-word group is highly frequent.] For comparability to the consonants task, we removed all repetitions after the first time the three-word sequence was copied. 

Importantly for the present purpose, fluent copying and pausing may be thought of as a function of (1) the familiarity with the letter sequences and (2) the participant's memory span and typing skill; for example touch-typists may depend less on memory representation of the to-be typed bigrams for fluent copying than hunt-and-peck typists. This results in a combination of fluent typing and typing interruptions. In other words, for these tasks we need to be able to disentangle fluent and disfluent IKIs.

Bayesian models, as used in this paper, are ideal for the reliable estimation of parameter values expressed as probability distribution rather than point estimates [@farrell2018computational; @gelman2014; @lee2014bayesian]. To achieve this, Bayesian models require the explicit inclusion of prior information, i.e. existing knowledge about parameter values. For small data sets non-uninformative priors influence the inferred parameter estimates (known as posterior) but for larger data sets vague priors are quickly overcome by the data [i.e. automatic Ockam's razor; @jefferys1992ockham] so that the choice of priors values impacts the posterior to a lesser extent. In the present paper, priors are used to aid model convergence by constraining the parameter space [i.e. using weakly regulating priors; @lambert2018student; @mcelreath2016statistical]. Priors are described in the modelling section. The predictive performance (i.e. fit) of these models is compared in the Results section.


# Results

## Data overview

The IKI data for the LF-bigrams task and the consonants task are visualized in Figure \ref{fig:descriptives}. The upper panels of the LF-bigrams task and the consonants task in Figure \ref{fig:descriptives}A show the data for each participant. In the lower panels of Figure \ref{fig:descriptives}A, different measures of central tendency are shown. The density function of the IKI data are shown in Figure \ref{fig:descriptives}B with vertical lines corresponding to the central tendency measures in Figure \ref{fig:descriptives}A.





\blandscape
```{r descriptives, fig.pos="bp!", fig.height = 4.5, fig.width = 9, fig.align = "center", fig.cap="Data overview. Plot A illustrates IKIs over bigram position (time-course) by participant in the upper rows and as different measures of central tendency (with standard error [SE]) in the lower rows for each the LF-bigrams task and the consonants task. Plot B shows the density distribution of IKI data with the same central-tendency descriptors as in plot A."}
#\clearpage
#\pagenumbering{gobble}
#\thispagestyle{empty}
source("scripts/get_descriptives_plot.R");plots_all
#\pagenumbering{arabic}
#\clearpage
```
\elandscape


These visualisation highlight two important points for the present data that were discussed in the introduction section: (1) aggregating data neglects individual time-course variability in the data; (2) the choice of central-tendency measure leads to different conclusions about the data. As for the first point, Figure \ref{fig:descriptives}A shows that participants slowdowns and speedups throughout the trial but do not show consistent patterns for the same letter bigrams as might be concluded from the corresponding summary statistics. If we disregard by-participant variability, central-tendency measures in the lower panels of Figure \ref{fig:descriptives}A suggest that some slowdowns and speedups might be bigram specific. For example, in the LF-bigrams task, the first bigram is followed by a faster IKI; in the consonants task, the first bigram is followed by a slowdown. Importantly though, there is a substantial variability between participants. 


As for the second point, the choice of central-tendency measure might affect whether we consider an observation a disfluency, or a participant to be prone to disfluent typing. In particular, means are systematically longer than the median and mode. Figure \ref{fig:descriptives}B illustrates why this is the case. Shown are the density functions for the LF-bigrams and the consonants task. Even log-scaled data show skewed distributions with a heavy right tail. While in a normal distribution the mean, median and mode have identical values, the conceptual differences between these three measures of central tendency lead to different values in non-normal distributed data. In particular, means are known to be sensitive to extreme values; these are inevitable for zero-bound IKIs with, in principle, no upper bound. For keystroke data, large means might be the consequence of a few larger IKIs that over-shadow largely normal typing behaviour. Means are closer to the horizontal middle of the data space which, for right-skewed distributions, is on the right of the distribution's peak (the value with the highest kernel density). The latter is being represented by the mode. Regardless of which measure is used, all three central tendency indicators ignore important properties of the distribution. That is, measures of central tendency neglect the variability in the data; keystroke data might indeed represent a combination of processes; e.g. normal typing and disfluencies. Central tendency measures do not allow us to distinguish between IKIs that are the results of fluent typing and IKIs that reflect process lags. 


For our data, aggregation does not just neglect participant-specific typing patterns but the choice of central-tendency measure leads to different conclusions about the data (e.g. which IKIs can be considered pauses). To ensure accurate statistical inference, we need to be able to account for participant-specific typing patterns as expressed across the typing time-course.



## Model fit

All models were implemented as Bayesian models [see e.g. @gelman2014; @lambert2018student; @mcelreath2016statistical] in the probabilistic programming language Stan [@carpenter2016stan; @rstan; @rstan2; @hoffman2014no]. Data, *R* scripts and Stan code are available on OSF ([osf.io/y3p4d/?view_only=2fe3472b599e4b53a17c461f44969aae](https://osf.io/y3p4d/?view_only=2fe3472b599e4b53a17c461f44969aae)). Also we produced a detailed walk-through document that shows how *R* can be used to apply the Stan code of a mixture model to copy-task data ([brave-khorana-9759fc.netlify.app/](https://brave-khorana-9759fc.netlify.app/)).^[Both links are clickable and anonymised for blind peer review.] Models were fitted with 30,000 iterations (15,000 warm-up) on 3 MCMC chains. Convergence was tested via the Rubin-Gelman statistic [@gelman1992], trace plots and cross-validation [@vehtari2015pareto; @vehtari2017practical].

The predictive performance of the models was established using leave-one-out cross-validation. Cross-validation penalizes models with more parameters and therefore prevents overfit [see @farrell2018computational; @mcelreath2016statistical; @lambert2018student; @lee2014bayesian]. The out-of-sample predictive performance was determined via Pareto smoothed importance-sampling [@vehtari2015pareto; @vehtari2017practical] and estimated as sum of the expected log predictive density ($\widehat{elpd}$). $\widehat{elpd}$ was used to compare the predictive quality of our models. Model comparisons can be found in Table \ref{tab:modelcomparisons}. Model comparisons revealed higher predictive performance for both mixture models M3 and M4 for both copy-task components. The increase in predictive performance is larger for the LF bigrams task compared to the consonants task. The differences in predictive performance of all models shows the same pattern in both copy-task components. For both tasks, the combination of the mixture model and the autoregressive-process model as implemented in model M4 (see equation \ref{eq:mog}) revealed the highest predictive performance with a small advantage over mixture model M3 (see equation \ref{eq:mogark}). We therefore chose model M4 for parameter evaluation of both copy-task components. 


```{r modelcomparisons, results = "asis"}
source("scripts/get_loo_table.R")

papaja::apa_table(looc[-1], align =  "lllrr", escape = FALSE, placement = "bp!",
                  row.names = T, stub_indents = list(`Consonants` = 1:4, `LF bigrams`= 5:8),
                  caption = "Model comparisons expressed as expected log predictive density ($\\widehat{elpd}$). The top row of each copy-task component shows the model with the highest predictive performance. Differences in predictive performance are shown as $\\Delta\\widehat{elpd}$ contrasting for each copy-task component the model in the first row and the remaining models. Standard errors (SE) are shown in brackets.",  
                  note = "LMM = Linear mixed-effects models; AR = Autoregressive model; MoG = Mixture of log-Gaussians") 

```


```{r}
#source("scripts/get_posterior.R")
source("scripts/get_posterior_LF_cons.R")
```


## Parameter evaluation

The copy-typing process can be characterized by the posterior of the mixture model's parameter values. These parameters values are summarised in Table \ref{tab:modelparameters} and in Figure \ref{fig:parameters}. Table \ref{tab:modelparameters} summarises the population and variance estimates as posterior mean with 95% probability intervals (PI). Estimates are shown for the LF-bigrams task and the consonants task. After accounting for process disfluencies, keystroke intervals were longer for the consonants task (`r beta_sum[1]` msecs, PI [`r beta_sum[2]`, `r beta_sum[3]`]) compared to the LF-bigrams task (`r beta_sum[4]` msecs, PI [`r beta_sum[5]`, `r beta_sum[6]`]). The slowdown for disfluencies was about four times longer for the consonants task. For the LF-bigrams task, the model determined a slowdown of `r delta_sum[4]` msecs (PI [`r delta_sum[5]`, `r delta_sum[6]`]) with a probability of `r theta_sum[5]` (PI [`r theta_sum[6]`, `r theta_sum[7]`]); for the consonants task we found a slowdown of `r delta_sum[1]` msecs (PI [`r delta_sum[2]`, `r delta_sum[3]`]) with a probability of `r theta_sum[1]` (PI [`r theta_sum[2]`, `r theta_sum[3]`]). In other words, in the consonants disfluent keystroke transitions were three times more likely to occur than fluent transitions; in the LF-bigrams task, only one out of three transitions constitutes a disfluency. The size of the slowdown in the consonants task suggest higher level processes such as reading of the target string. This is unlikely to be the case for the short slowdown in the LF-bigrams task. Instead, the slowdown in the LF-bigrams task might be a bigram-frequency effect. Four out of 16 bigrams in the LF-bigrams have a low frequency (i.e. $\frac{4}{16}\approx0.19$). In other words, the magnitude for disfluencies and hence their cognitive source in the typing process is task-specific. Further autocorrelation between subsequent keystrokes was non-different from zero in the LF-bigrams task; keystroke transitions in the consonants task were in general followed by a `r phi_sum[1]` times faster keystroke transition; PI [`r phi_sum[2]`, `r phi_sum[3]`]. Variance components are reported for completeness. 



```{r modelparameters, results = "asis"}
source("scripts/get_posterior_table.R")
param_table %<>%
  pivot_wider(names_from = Comp, values_from = c(M, lo, up)) %>%
  mutate(id = c(1, 2, 4, 3, 5, 6, 9, 10, 7, 8)) %>%  arrange(var_comp, id) %>%
  select(-var_comp, -id) %>%
  select(Param, ends_with("LF"), ends_with("Consonants"), description) %>%
  unite("LF bigrams", M_LF:lo_LF, sep = " [") %>%
  unite("LF bigrams", `LF bigrams`:up_LF, sep = ", ") %>%
  mutate(`LF bigrams` = paste0(`LF bigrams`,"]")) %>%
  unite("Consonants", M_Consonants:lo_Consonants, sep = " [") %>%
  unite("Consonants", `Consonants`:up_Consonants, sep = ", ") %>%
  mutate(`Consonants` = paste0(`Consonants`,"]"),
         Param = paste0("$",Param,"$"),
         Param = paste0(Param, " (", tolower(description), ")")) %>%
  select(-description) %>%
  rename(Parameter = Param)

papaja::apa_table(param_table, align =  "lrr", escape = FALSE, placement = "bp!", row.names = T,
                  stub_indents = list(`Population estimates` = 1:4, `Variance estimates`= 5:10),
                  caption = "Parameter estimates with 95\\% PIs separated into population estimates and estimates for variance components. Parameters are shown as used in equations with a brief description of their conceptual meaning in parentheses. Estimates are shown for the LF-bigrams task and the consonants task.") 

```


Figure \ref{fig:parameters} summarises by-participant model estimates. The modelled IKIs for fluent typing are shown in Figure \ref{fig:parameters}A. This figure shows the estimated typing speed of each participant (i.e. a random sample of 75 participants for visualisation) after accounting for typing disfluencies. Each horizontal line represents the statistically inferred estimate for a participant. The vertical dotted line shows the estimated population mean. Figure \ref{fig:parameters}B shows the disfluency probabilities, i.e. the probability to exhibit a typing disfluency for each participant. For each participant the model captures varying pausing probabilities that express individual but also task-specific typing difficulty. Although, on the population level, disfluencies are likely to occur in the consonants task, not all all participants show a more disfluent than fluent keystrokes (as indicated by individual estimates below 0.5 in Figure \ref{fig:parameters}B representing a larger probability of fluent keystroke transitions) or more disfluencies in the consonants task than in the LF-bigrams task. In fact, some participants paused more often in the LF-bigrams task than in the consonants task (see Figure \ref{fig:parameters}E).


\blandscape
```{r parameters, fig.pos="bp!", fig.height=4.5, fig.width=9, fig.align = "center", fig.cap="By-participant parameter values for LF-bigrams and consonants task. Plot A and Plot B show the average IKIs for fluent typing and disfluency probabilities, respectively, for each participant (for a random subset of 75 participants for illustration); error bars indicate 95\\% PIs, dotted vertical line shows the population estimate. Plot C--E show correlations (red line) between by-participant mean-posterior estimates of the consonants task and the LF-bigrams task for fluent typing (C), the autoregressor (D), and the disfluency probability (E)."}

n_ppts <- 75; source("scripts/get_posterior_plot3.R"); plots_post
```
\elandscape

Figure \ref{fig:parameters}C-E show between LF bigrams and consonants correlations for the by-participant estimates of the fluent-typing interval duration (C), the autocorrelation between subsequent keystroke intervals (D), and the disfluency probability. The correlations show that individuals with longer keystroke intervals for the LF-bigrams task also show longer keystroke intervals in the consonants task (Figure \ref{fig:parameters}C); a similar relationship can be seen for autoregression although in the consonants task participants generally show faster keystroke intervals across bigrams while for the LF bigrams task some participants speedup and other slowdown (Figure \ref{fig:parameters}D). No such correlation was found for the disfluency probability (Figure \ref{fig:parameters}E). Participants that exhibit many disfluencies in the consonants task do not necessarily show more disfluencies in the LF-bigrams task. In other words, the model parameters do not just capture individual differences but also task-specific differences with regards to typing speed and pausing behaviour.


```{r}
# intercepts vs autoregression
#The second best performing model, for both copy-task components, is the mixture model M4 with an by-participant autoregressor for fluent typing only. Adding the autoregressor instead of random bigram intercepts for fluent typing did not improve the predictive performance of the mixture model per se. In fact, the autoregressive model was found to be the model with the lowest predictive performance. Modelling bigrams as random intercepts (with and without by-participant slope adjustments) was found to have a higher predictive performance compared to the autoregession model. However a higher predictive performance for M4 suggests that addressing the dependence of subsequent IKIs increases the predictive performance only then, if we limit the autocorrelation assumption to those keystroke transitions that were assumed to be non-disfluent. Alternatively, modelling IKIs as coming from a mixture of fluent typing and process disfluencies might lead to a higher predictive performance regardless of how we treat inter-bigram variations. In fact, this was the case for the consonants-task data reflected in the negligible differences between mixture model M3 and M4 in consonants-task data but not in the LF-bigrams task data. If the majority of keystroke transitions are disfluent, as we will see in the following for the consonants-task data, we would expect no notable difference between M3 and M4.

```



Faster participants might, in principle, show larger disfluency magnitudes; i.e. the size of the disfluency magnitude may vary by participant. To test this possibility we also implemented two models that are largely identical to model M3 (see equation \ref{eq:mog}): first, we allowed both the disfluency probability $\theta$ and the disfluency magnitude $\delta$ to vary by participant; second, $\delta$ but not $\theta$ was allowed to vary by participant. We compared the predictive performance of either model to model M3. Neither model was convincingly better than model M3, neither for the consonants task nor for the LF-bigrams task. For the consonants data, allowing $\delta$ and $\theta$ to vary by participant resulted in negligibly better predictive performance compared to model M3 ($\Delta\widehat{elpd}$=`r abs(mc_cons$elpd_diff[2])`, SE=`r mc_cons$se_diff[2]`); holding the disfluency probability $\theta$ constant while allowing the disfluency magnitude $\delta$ to vary by participant revealed a lower predictive performance ($\Delta\widehat{elpd}$=`r mc_cons$elpd_diff[4]`, SE=`r mc_cons$se_diff[4]`). The same patterns was found for LF bigrams: allowing $\delta$ to vary rendered no predictive gain ($\Delta\widehat{elpd}$=`r mc_lf$elpd_diff[2]`, SE=`r mc_lf$se_diff[2]`); fixing $\theta$ and allowing $\delta$ to vary showed a decrease in predictive performance ($\Delta\widehat{elpd}$=`r mc_lf$elpd_diff[4]`, SE=`r mc_lf$se_diff[4]`). This comparison suggests that it is not the magnitude of the disfluencies ($\delta$) that varies across participants but the disfluency probability (mixing proportion $\theta$).


Overall, the values of the three process-central model parameters -- fluent typing speed, disfluency probability, and slowdown magnitude for disfluencies -- were found to be task sensitive. The LF-bigrams task shows shorter typing intervals, a lower disfluency probability compared to the consonants task and a shorter slowdown magnitude for typing disfluencies. Individual typing style was characterized by random variation in typing speed and in the probability but not in the magnitude of process disfluencies. 

```{r}
# There was no evidence for a relationship between typing speed and disfluency probability that would suggest a trade-off between planning and execution.

# Otherwise keystroke intervals wouldn't be different across tasks, only pausing

#Also, subsequent keystroke pairs were negatively related for consonants but this relationship varied across participants in the LF-bigrams task. 

```



# Discussion

Our aim was to provide a statistical model that allows to account for process disfluencies in keyboard-typing data. To address this aim we tested a series of Bayesian models on a lexical and a non-lexical copy-typing task. Model comparisons revealed that finite mixture models provided a better fit to inter-keystroke intervals of both copy-tasks compared to standard linear mixed-effects models. In other words, we showed that, among the models tested, data from copy-typing can be modelled best as a combination of fluent and disfluent typing intervals by means of an unknown individual mixing weight. We demonstrated how the model posterior can be used to infer estimates for three typing characteristics for individual participants and on the population level.


The best fitting model summarizes the typing process as a function of three process-relevant parameter values. Those are: (1) the population-level and by-participant keystroke transitions for fluent typing after accounting for process disfluencies; (2) population-level and by-participant mixing proportions indicating the probability of disfluent keystroke transitions; (3) the population-level disfluency magnitude, i.e. slowdown in keystroke transitions. These parameter estimates are interesting for two reasons: first, they allow us to characterize the writing task at hand as a mixture of fluent and disfluent keystroke transitions as represented in Figure \ref{fig:modelv2}^[This model is just one possibility of how the mixture-model parameters map onto copy-typing. Disfluencies might as well arise on a lower level, for example, when the typist is struggling to find the correct key]; second, by-participant parameter estimates allow us to extract characteristics for individual typists. On the basis of the population-level and individual parameter estimates, we can determine whether an individual is a fast / slow typist or has unusually high / low probability to exhibit disfluencies compared to the population estimates. Thus, the model can be used diagnostically to identify participants with larger disfluency probabilities or to compare pausing across groups of participants.


```{r modelv2, fig.pos="bp!", fig.height = 3.5, fig.width = 6.5, fig.align = "center", fig.cap="Basic model of copy typing with mixture-model parameters. Disfluencies are the sum of $\\alpha$ and $\\delta$, where $\\delta$ is the additional time that results from updating the letters buffered for motor encoding. The probability of disfluencies is indicated as $\\theta$ mapping onto looks to the target string."}
include_graphics("spelling_decision_probs.pdf")
```



The strength of this model is that it allows us to characterize the writing process and detect disfluencies in a principled way in line with what we know about keyboard typing. In particular, keyboard typing can be thought of as a process in which information cascades from higher to lower levels of activation; process inhibition on higher levels causes lags downstream. We have captured this process by characterizing the typing process as a mixture of fluent and disfluent keystroke transitions. Typing speed and the proportion of disfluent transitions depend on each typist's copying style. This is important because not distinguishing between between fluent and disfluent keystroke transitions can lead to incorrect inference about fluent typing. For example, collapsing across fluent and disfluent transitions might lead to the conclusion that task-related difficulty impacts on the execution of keystrokes even though the overall increased keystroke-transition duration was in fact the results of more frequent and longer pauses while typing speed itself may remain constant. From the present analysis we know that merely one-quarter of the data from the consonants task and two-thirds of the data from the LF-bigrams task were found to correspond to fluent keystroke transitions. Even after accounting for disfluent keystroke transitions, fluent typing was found to be two times slower in the consonants task compared to the LF-bigrams task. Not accounting for task-specific disfluency probabilities would result in biased estimates and, therefore, affect conclusions about task-related difference in typing speed. 

Our results suggest that the probability and size of disfluencies are sensitive to task related factors. In the consonants task, disfluencies are indeed more probable than fluent transitions. This was not the case in the LF-bigrams task. Across participants the probability of typing disfluencies was relatively homogeneous in the LF-bigrams task but showed a larger variability in the consonants task. Similarly the average by-participant typing speed was more diverse in the consonants task compared to the LF-bigrams task. This contrast might be the result of a larger range of strategies that participants applied to copy consonant sequences than when copying the word triplet in the LF-bigrams task. For example, participants may have used *n*-grams (one letter at a time or more) or spaces to chunk consonants before generating motor codes; in the lexical LF-bigrams task, word(s) or the entire phrase are better candidates for chunking than individual letters.

The variability in typing strategies across the sample may be understood as a function of typing skills and cognitive factors. For example, non-touch typists depend on memory resources to correctly copy the target string. This is because participants with poor typing skills have to shift gaze between keyboard and text more often than touch typists. Consequently, memory resources are more important for poor typists such that participants with a shorter memory span might update their memory representation of the target string more frequently than participants with a long memory span expressed as an increased disfluency probability. This might be less important for the typing performance of touch typists to the extent that touch typists have less need to search for keys corresponding to target letters. In contrast, the lower variability found for the LF-bigrams task can be understood as a more uniform use of copy-typing strategies across participants. Copy-typing strategies might have been more consistent for the LF-bigrams task because participants, especially those with poor typing skills, can make use existing knowledge (e.g. lexical meaning of words, motor codes for bigrams) to relief memory demands. This is not possible for the consonants task. However, our results did not support a trade-off between typing speed and disfluency probability. This might be because disfluencies are not merely the result of a memory-representation update but are also related to difficulty finding the correct key and individual memory-span differences. Therefore the disfluency probability can be understood as an estimate for all non-typing related activities. As such the disfluency probability may be an indicator of memory span [@grabowski2010second;@olive2014toward], low level reading skill [@de2018exploring] and individual typing skills.


```{r}
#Every statistical model rests on decisions that were during the modelling process that would allow for alternative options. In particular, we modelled fluent and disfluent keystroke intervals as following a log-Gaussian distribution. Alternatively @chukharev2014pauses used an ex-Gaussian, an exponentially modfied Gaussian, model to model keystroke intervals. This approach accounts for heavy-tailed distributions by including a scale parameter.

# Accounting for pauses
# Almond et al 2012: mix of log-gaussian
# Guo et al 2018: log-gaussian vs stable distribution (heavy tailed distributions)
# Chukharev 2014: ex-Gaussian
# Baaijen et al. 2012: mixture model for text writing for individual ppts

```




The central advantage of using mixture models to account for typing disfluencies is that we can by-pass threshold values to define disfluencies and include it as individual typing-skill property in the analysis of writing-process data. Mixture models provide estimates for fluent typing while accounting for disfluencies by modelling fluent and disfluent typing as a mixture process. At the same time, mixture models provide disfluency estimates as expression for individual and task-specific typing difficulty. It is impossible to know the upper bound for fluent and the lower bound for disfluent transitions from screening keystroke data. Using threshold values ignores that some participants are generally slower typists and some tasks are more difficult. Mixture models allow us to capture disfluencies as a latent process in a principled manner. This is important because disfluencies must be understood as relative to an individuals' typing speed given the task at hand [@wen06]. Therefore, mixture models allow us to test predictions about typing disfluencies in certain populations such as learning typists, L2 typists and individuals with genuine typing difficulty after account for individual differences in typing speed or vice versa. For example, some individuals that might be classified as having typing problems might not have excessive numbers of pauses but merely longer key transitions, while normal typists use pauses to prepare larger linguistic units. In other words, the presented model can be used to test hypotheses about psychological factors (e.g. memory demands, writing experience, proficiency in writing in a second language) that might affect the ratio of disfluencies in the writing process. If disfluencies are crucial to identify poor typists in a sample, mixture models might be used as diagnostic tool. Also, mixture models allow us to directly test whether the number of disfluencies can be changed as response to an keyboard typing intervention. As an avenue for future research, mixture models as presented in this paper can be used for different types of writing tasks and particular populations.




Writing involves processing on various levels of mental representation. As activation cascades from higher to lower levels of representation, a delay on any of these levels causes disfluencies. While we modelled this process as a binary distinction between fluent and disfluent typing, processing difficulty on different levels might be associated with different disfluency magnitudes and might be cumulative. If the size of the disfluency is assumed to depend on the inhibited process upstream or combination of processes, this can be implemented as additional mixture component(s) [similar to @baaijen2012keystroke; see also @almond2012preliminary] to address different types of disfluencies [@medimorec2016effects; @medimorec2017disfluency; @wengelin2001disfluencies]. In other words extensions of mixture models allow us to test different hypotheses about the cascade of processes involved in writing and language production. 




# References
```{r create_r-references, echo=FALSE, include=FALSE}
r_refs(file = "ref.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
  
<div id = "ref"></div>
\endgroup
  


