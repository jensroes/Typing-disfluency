---
title             : "Modelling disfluencies in copy-typing"
shorttitle        : "Modelling disfluencies in copy-typing"

author: 
  - name          : "Jens Roeser"
    affiliation   : "1"
    address       : "50 Shakespeare St, Nottingham NG1 4FQ"
    corresponding : yes    # Define only one corresponding author
    email         : "jens.roeser@ntu.ac.uk"
  - name          : "Sven De Maeyer"
    affiliation   : "2"
  - name          : "MariÃ«lle Leijten"
    affiliation   : "3"
  - name          : "Mark Torrance"
    affiliation   : "1"
  - name          : "Luuk Van Waes"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Nottingham Trent University, United Kingdom"

  - id            : "2"
    institution   : "Faculty of Social Sciences, University of Antwerp, Belgium"

  - id            : "3"
    institution   : "Department of Management, University of Antwerp, Belgium"


abstract: |
   The analysis of keystroke latency data typically involves the calculation of summary statistics such as the mean inter-keystroke interval, pause frequencies etc. There are two fundamental problems with this: first, summary statistics ignore important information in the data and frequently result in biased estimates; second, pauses and pause-related measures are defined using threshold values which are, in principle, arbitrary. We implemented a series of Bayesian models that aimed to address both issues by providing reliable estimates for individual typing speed and statistically inferred process disfluencies. We tested these models on a random sample of 250 participants from the Dutch copy-task corpus. Our results illustrate that process disfluencies can be statistically captured as a mixture process of fluent and disfluent typing. Mixture models provide a principled approach to detect disfluencies in keyboard typing data.


keywords: "Copy-task; keystroke modelling; autoregression; mixture models; Bayesian statistical models; typing skills"


bibliography      : ["ref.bib"]


documentclass     : "apa7"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    keep_tex: TRUE
#  papaja::apa6_docx:
#    keep_tex: TRUE
#    reference_docx: template_flr.docx



figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

header-includes:
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{threeparttable}
  - \usepackage[normalem]{ulem}
  - \usepackage[utf8]{inputenc}
  - \usepackage{icomma}
---

```{r setup, include=FALSE}
library(magrittr)
library(tidyverse)

library(papaja)
library(knitr)
library(citr)
library(kableExtra)

library(tidybayes)
library(grid)
library(gridExtra)
library(ggstance)
library(ggforce)
library(ggthemes)
library(ggExtra)
library(cowplot)

source("../functions/functions.R")
source("../functions/get_data.R")

knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE,
                      cache.extra = R.version,
                      dev = "cairo_pdf"
                      )
options(kableExtra.auto_format = FALSE)
dev.args = list(pdf = list(type = "cairo"))

theme_set(theme_few(base_size = 9) + theme(axis.ticks = element_blank(),
                                           legend.position = "top",
                                           legend.justification = "right"))

mycolours = c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

posn.j <- position_dodge(width = 1)
label = "Copy-task\ncomponent: "

```


# Introduction

Writing research has made extensive use of keystroke-logging to capture typing process data. In particular process disfluencies (loosely defined as relatively long intervals between subsequent keystrokes) are interesting to develop an understanding of an individuals writing progress. This is because language production is typically thought of as a cascade from the mental generation of a message, into grammatical processing and finally the generation and execution of motor codes that serve the transmission of an idea. This can be found in theoretical models of speech [@bock2014syntactically], handwriting [@van1991handwriting] and keyboard typing [@hayes2012evidence]. Disfluencies at the execution stage are therefore indicators of process demands that arise on higher levels of mental representation [@christiansen2016now;@olive2014toward]; for example when preplanning syntactic dependencies [@roeser2019advance] or retrieving the lexical entry of a word or its spelling [@torrance2016adolescent]. At present there is no principled way for detecting keystroke lags that can be considered a process disfluency. In this paper we present a series of statistical models that aim to capture process disfluencies and produce individual estimates of typing performance.


Keystroke logs provide rich information about the typing process. From these log, researchers can calculate different process measures including measures of writing fluency [@chukharev2019combined; @van2015fluency; @medimorec2016effects; @medimorec2017disfluency]. To name a few, researchers have performed data analysis on means, medians and standard deviations (SD) of inter-keystroke intervals (the latency between two consecutive keystrokes), number of pauses or pause duration and within-word keystroke intervals [for an overview of frequently used keystroke measures see @conijn2019understanding]. @conijn2019understanding suggested that these aggregates are sensitive to processing difficulty that arises on different levels of mental representation. However, there are two substantial problems tight to the use summary statistics to develop an understanding of the typing process. 

First, pause frequencies, writing bursts and related measures are used to assess writing performance [e.g. @alves2015progress; @beers2017effects; @zhang2019there]. These measures require a definition of what passes as a pause [@wen06;@van2016keystroke], i.e. a pause criterion threshold often set to 2 secs [@chanquoy1996writing; @kaufer1986composing; @sullivan2002self;@wen02] or some other lower bound [@chukharev2014pauses; @connelly2012predicting; @leijten2013keystroke]. Researchers have stipulated pause thresholds specific to their research purposes and based on prior research. However, ideally, this threshold would need to be specific to both the writing task and the skills of the typist [@wen06]. For example, when comparing the frequency of pauses larger than 2 secs for a dyslexic and a normal typist, one might observe more pauses for the dyslexic because 2 secs are indeed not unusual transitions between two keystrokes for a dyslexic writer or pauses for the normal typist are typically shorter than 2 secs and therefore unobserved given a 2 secs pause criterion [@wengelin2001disfluencies]. This bias would also affect the interpretation of results from L2 typists and other threshold criteria [@van2015fluency].

Second, data aggregation results in the loss of important information about disfluencies and time course variation. Even if this variation is not of interest to a research question, parametric aggregates such as mean and SD, and even non-parametric descriptives such as median and IQR, are biased estimates. This is because mean and median are representative for the centre of a normal distribution but keystroke intervals are non-normal distributed as they are zero-bound and therefore right-skewed.^[In fact, the minimum size of keystroke intervals is a function of the time it takes to plan and execute the motor program and keyboard polling.] Therefore, data aggregation may lead to incorrect inference based on biased parameter values [@baaijen2018discovery]. To prevent biased parameter values researchers used data transformation and data trimming [@hoaglin1987fine] to remove data that were _a priori_ considered outliers. The removal of such values will inevitably impact differently on struggling writers and normal writers, skew the resulting typing estimates and therefore potentially the conclusions drawn from the data.

A central methodological challenge with implications for writing research [@hayes2012evidence; @kaufer1986composing; @wen06; @van2016keystroke] is the detection of writing disfluencies. We addressed this problem by implementing statistical models that aim to capture the nature of the data generating process (i.e. keyboard typing). Crucially we want these models to provide reliable estimates of typing performance without subjecting the data to trimming and threshold criteria, aggregation or manual manipulation.




# Modelling typing process data

As a guiding principle, we aim to produce statistical models that are in line with the assumed mental process that generates the data. Keystrokes are the end of a cascade of mental processes. The typing process is measured as lags between subsequent keypresses, for example, the transitions c$^{\wedge}$a$^{\wedge}$t for the word _cat_ where $^{\wedge}$ respectively indicates the inter-keystroke interval (IKI) between pressing $<$c$>$ and $<$a$>$, and $<$a$>$ and $<$t$>$. Keystroke intervals reflect at minimum two states of the information flow from higher to lower levels of activation, i.e. either information can flow or is being inhibited. The latter is then resulting in process disfluencies expressed in larger lags between subsequent keys. Our models should provide a systematic way of addressing process disfluencies; e.g. when the lag before pressing $<$a$>$ is unusually large. We implemented a series of models for keystroke. The quality of fit of these models is compared in the Results section.

Statistical models can be used to characterize an underlying data generating process as a function with parameter values. For example, if we assume that there is a single underlying process that generates normal distributed data, we can discribe this process with a mean $\mu$ and a variance $\sigma^2$. The values of the parameters $\mu$ and $\sigma^2$ are unknown and often expected to vary across task demands and populations. The model of the data can be written as $y \sim Normal(\mu, \sigma^2)$; i.e. the data $y$ come from a single process that follows a normal distribution with an unknown mean $\mu$ and an unknown error variance $\sigma^2$. Our statistical model will then determine values for these parameters that can be considered reliable if the data satisfy the model assumption; i.e. the data come from a single process that generates normal distributed data.

Bayesian models, as used in this paper, are ideal for reliable parameter estimation as they allow us to derive a probability distribution of the parameter value of interest [@farrell2018computational; @gelman2014; @lee2014bayesian]. To achieve this, Bayesian models require the explicit inclusion of prior information, i.e. existing knowledge about parameter values. For small data sets non-uninformative priors influence the posterior (inferred parameter estimates) but for larger data sets the prior is quickly overcome by the data [i.e. automatic Ockam's razor; @jefferys1992ockham] so that the choice of priors (reflecting existing knowledge) is of less influence for the posterior. In the present paper, priors are used to aid model convergence by constraining the parameter space [i.e. using weakly regulating priors; @lambert2018student;@mcelreath2016statistical]. 

We assume throughout that IKIs can be characterized as log-normal distributed because IKIs are zero-bound [@baa08book]. To be able to estimate the parameter of interests, e.g. the mean $\mu$, we need a model that accounts for other sources of variance. This can be achieved with linear mixed effects models (LMM) which have been used to model keystroke data [@leijten2011coordinating;@quene2004multi; @waes2019; @van2010reading]. The LMM in equation \ref{eq:lmm} is an extension of the simple example above. Sources of random error variance in this model are participants $u$ and keystroke bigrams $w$.

$$
\tag{1}
\begin{aligned}
y_{ij} \sim LogNormal(\mu + u_i + w_j, \sigma_e^2)\\
\end{aligned}
(\#eq:lmm)
$$

We know that some participants are faster typists than others and some bigrams are easier to type than others. Differences associated with participant $i$, expressed as $u_i$, can be assumed to be normal distributed around 0 with a between participants variance $\sigma_u^2$ with $i = 1, \dots, I$, where $I$ is the number of participants (see \ref{eq:lmm2}). The variance $\sigma_u^2$ is given a half-Normal prior (because a variance is never negative) with a mean of 0 and a variance of 2.5.


$$
\tag{2}
\begin{aligned}
u_i \sim Normal(0,\sigma_u^2)\\
\sigma_u \sim Normal(0,2.5)\\
\text{constraint: } \sigma_u >0 
\end{aligned}
(\#eq:lmm2)
$$

Variation between keystroke pairs (i.e. letter bigrams) $w$ is added as random intercepts term in equation \ref{eq:lmm} [@van2019multilingual;@waes2019]. More specifically, this is to assume that each bigram $j$ with $j = 1, \dots, J$, where $J$ is the total number of bigrams, is independent of the other bigrams. Each bigram intercept difference $w_j$ is distributed around 0 with a between bigram variance $\sigma_w^2$ (equation \ref{eq:lmm5}). 

$$
\tag{3}
\begin{aligned}
w_j \sim Normal(0,\sigma_w^2)\\
\sigma_w \sim Normal(0,2.5)\\
\text{constraint: }\sigma_w >0 
\end{aligned}
(\#eq:lmm5)
$$

In other words, the parameter estimate for the mean $\mu$ in equation \ref{eq:lmm} is the marginalised value after taking into account random variation between participants $u$ and bigrams $w$. To aid effective sampling, we non-centred the mean $\mu$ in all models with regulating priors [equation \ref{eq:lmm3}; see @lambert2018student].

$$
\tag{4}
\begin{aligned}
\mu = \alpha_{\mu} + \sigma_{\mu} * \mu_{\text{raw}}\\
\alpha_{\mu} \sim Normal(5,2)\\
\sigma_{\mu} \sim Normal(0,1)\\
\mu_{\text{raw}} \sim Normal(0,1)\\
\text{constraint: }\mu_{\sigma}>0 
\end{aligned}
(\#eq:lmm3)
$$

For the unexplained variance $\sigma_e^2$ we used an uninformative half-Cauchy prior [equation \ref{eq:lmm4}; see @gelman2014]. 

$$
\tag{5}
\begin{aligned}
\sigma_e \sim Cauchy(0,2.5)\\
\text{constraint: }\sigma_e>0 
\end{aligned}
(\#eq:lmm4)
$$

Further, we can extend this model by assuming that larger variations in typing differences for bigrams depend on the typing speed of each participant. For example, fast participants might show less variation between bigrams than slow participants. This assumption can be modelled by including by-participant slope adjustments for bigrams by introducing a variance-covariance matrix $\Sigma_u$; LKJ prior with $\nu=2.0$ [@lewandowski2009generating; @sorensen2016bayesian]. 



## Typing as autoregressive process

The previous model captures variation associated with particular bigrams but assumes that disfluencies are subject to random noise. Further, this analysis assumes that subsequent keystrokes are independent and thus exchangeable. IKIs are not necessarily independent; IKI$_{i}$ might be related to IKI$_{i-1}$ preceding it [@conijn2019typo]. In other words, we can predict an IKI with the previous keystroke and capture their relationship with a parameter $\phi$; see equation \ref{eq:ark}. This is called an autoregressive process [@eltahir2004dynamic]. This model captures disfluencies as slowdown relative to a previous keystroke. The autocorrelation was assumed to vary for each participant $\phi_i$ with a centred mean $\mu_{\phi}$ and error variance $\eta^2$. 

$$
\tag{6}
\begin{aligned}
y_{ij} \sim LogNormal(\mu + \phi_i*log(y_{ij-1}) + u_i, \sigma_e^2)\\
\text{where}\\
\phi_i \sim Normal(\mu_{\phi}, \eta^2)\\
\mu_{\phi} \sim Normal(0, 1)\\
\eta \sim Cauchy(0, 1)\\
\text{constraint: }\eta >0 
\end{aligned}
(\#eq:ark)
$$


## Typing as mixture process

Process disfluencies can also be captured in finite mixture models [e.g. @farrell2018computational; @gelman2014]. Mixture models allow us to model data as coming from a combination of processes. For the present purpose we constrain the model to be finite. In particular, we assume that the data come are mapping on fluent processes executions and inhibitions. In other words, we fixed the number of underlying distributions to two, namely 2 log-Gaussian (normal) distributions, of which one represents fluent typing (shorter IKIs) and the other represents disfluencies (longer IKIs). This model can be summarised as in equation \ref{eq:mog}, following @vasishth2017. The first and second line represent that the data $y$ are modelled as the sum of two weighted log-normal distributions of which the first distribution has a mixing proportion $\theta$ and the other distribution receives the remaining proportion $1-\theta$. Both distributions have the same mean $\mu$. The parameter $\delta$, constrained to be positive, was added to the first distribution to capture the latency magnitude of process disfluencies with $\theta$ indicating the probability of disfluencies to occur. The probability of disfluent IKIs $\theta_i$ was allowed to vary across participants $i$ as the amount of disfluencies observed can be assumed to depend on typing style.


$$
\tag{7}
\begin{aligned}
	y_{ij} \sim \theta_i \cdot LogNormal(\mu + \delta + u_i + w_j, \sigma_{e'}^2) +\\
		(1 - \theta_i) \cdot LogNormal(\mu + u_i + w_j, \sigma_{e}^2)\\
		\text{where}\\
		\delta \sim Normal(0,1)\\
		\text{constraint: } \delta > 0
\end{aligned}	
(\#eq:mog)
$$

As shown in equation \ref{eq:mog2}, a continuous prior was placed on the logit of the individual mixing proportions $\alpha_i$, which was transformed to a proportion, using the inverse logit function, and stored in $\theta_i$ to range between 0 to 1. We used a normal prior for the logit of individual mixing proportions $\alpha_i$ with a mean $\mu_{\alpha}$ that captures the logit of the population disfluency probability (with an error variance $\tau^2$). The hyper-prior on the population mixing proportion $\mu_{\alpha}$ was assumed to have a mean of logit 0, corrsponding to a probability of 0.5 with a variance of logit 1 (i.e. $\approx$ 0.73 in proportion).



$$
\tag{8}
\begin{aligned}
		\theta_i = Logit^{-1}(\alpha_i)\\
		\alpha_i \sim Normal(\mu_{\alpha},\tau^2)\\
		\mu_{\alpha} \sim Normal(0,1)\\
		\tau \sim Cauchy(0,1)\\
		\text{constraint: } \tau > 0
\end{aligned}	
(\#eq:mog2)
$$

As longer latencies are known to be associated with a larger variances for both response-time data in particular [@wagenmakers2007linear] and human motor behaviour in general [@wing1973response;@schoner2002timing], the variance $\sigma_{e'}^2$ associated with the distribution of typing disfluencies was constrained to be larger than the variance for normal typing $\sigma_e^2$ as shown in \ref{eq:mog3} [see @vasishth2017; @vasishth2017feature].

$$
\tag{9}
\begin{aligned}
		\sigma_{e'} = \sigma + \sigma_{\text{diff}}\\
		\sigma_{e} = \sigma - \sigma_{\text{diff}}\\
		\sigma_{\text{diff}} \sim Normal(0,1)\\
		\sigma \sim Cauchy(0,2.5)\\
		\text{constraint: } \sigma, \sigma_{\text{diff}}, \sigma_{e'}, \sigma_{e} > 0
\end{aligned}	
(\#eq:mog3)
$$


## Typing as autoregressive mixture process

The mixture model, as well as the LMM, imply that letter bigrams are independent. This might be the case for disfluencies but less likely so for subsequent IKIs in fluent typing which might involve autocorrelation. Therefore, we implemented another mixture model but replaced the bigram intercepts $w_j$, in the distribution that represents fluent typing in equation \ref{eq:mog}, with an autoregressor $\phi_i*y_{ij-1}$, as in equation \ref{eq:ark}; random bigram intercepts were kept for the distribution of disfluent typing intervals. 


```{r }
# Load df
path <- "../data/"
#d <- get_data(path = path) %>% filter(component == "Consonants") %>% select(-component)
d <- get_data(path = path) %>% filter(component %in% c("Consonants", "LF"), rep == 1) %>%
  select(subj, bg, bigram, IKI, sex, age, component)

d.ppt <- d %>% select(subj, age, sex) %>% unique()
d.sex <- d.ppt %>% count(sex) %>% pull(n) # femanle, male
d.age <- d.ppt %>% summarise(M = median(age), min = min(age), max = max(age)) %>%  gather(p, value) %>% pull(value) %>% round(0) 
```


# Method

To test which model captures the typing process best, we applied a series of models as described in the previous section to data from a subset of the Dutch copy-task corpus [@leijten2013keystroke;@waes2019;@van2019multilingual]. An overview of all models can be found in Table \ref{tab:models}.


```{r models, results = 'asis'}
models <- tibble(Models = paste0("M",1:5),
       Type = c("LMM", "LMM", "AR", "MoG", "AR + MoG"),
       Equation = paste0("\ \\ref{eq:", c("lmm", "", "ark", "mog", ""), "}"),
       Description = c("Random intercepts for bigram order",
                       "As M1; by-participant random bigram slopes",
                       "Autocorrelation between subsequent IKIs",
                       "Mixture process of normal and disfluent typing",
                       "As M4 but autocorrelation for normal typing")
                       ) 

models$Equation[c(2,5)] <- ""

papaja::apa_table(models,
                  align = c("l", "l", "l"), 
                  escape = FALSE, 
                  digits = 0,
                  placement = "!ht",
                  caption = "Overview of typing process models. All models were fitted with random intercepts for participants.",
                  note = "LMM = Linear mixed effects models; AR = Autoregressive model; MoG = Mixture of (log-)Gaussians"
                  ) 
```


The copy-task corpus consists of keystroke data collected via Inputlog, a Javascript-based web application available on \url{www.inputlog.net} with the source code released on [github.com/lvanwaes/Inputlog-Copy-Task](https://github.com/lvanwaes/Inputlog-Copy-Task) and [zenodo.org/record/2908966](https://zenodo.org/record/2908966). In a set of different subtasks participants have to produce keyboard typed responses. In this analysis we focus on the consonants task and the low-frequency (LF) bigrams task. In the consonant task, participants saw and copy-typed a single time four blocks of six consonant sequences; i.e. "tjxgfl pgkfkq dtdrgt npwdvf". This task allows us to measure typing skills in a non-linguistic environment [@grabowski2010second]. We repeated the analysis for the LF-bigrams task to contrast the non-lexical consonants task with a lexical copy task. In the LF-bigram task, participants typed three-word combinations seven times (*een chaotische cowboy* 'a chaotic cowboy' in the Dutch version) of which four bigrams are low frequent. For comparability to the consonant task, we used the data from all bigrams but removed all repetitions after the first time the three-word sequence was copied. Importantly for the present purpose, fluent copying and pausing may be thought of as a function (1) the complexity to the letter sequences and (2) the participant's memory span and typing skill; for example touch-typists may depend less on memory representation of the to-be typed bigrams for fluent copying than hunt-and-peck typists. This results in a combination of fluent typing and typing interruptions. In other words, for these task we need to be able to disentangle fluent and disfluent IKIs. We used a random sample of `r nrow(d.ppt)` participants (`r d.sex[1]` females, `r d.sex[2]` males, `r d.sex[3]` unknown) from the age range of `r d.age[2]` to `r d.age[3]` years (median age = `r d.age[1]` years). Before analysis we excluded spaces and editing operations from the data. To allow comparisons to the autoregressive models, all other models neglected the first IKI for every participant. 


# Results

## Data overview

The IKI data for the LF-bigrams task and the consonants task are visualized in Figure \ref{fig:descriptives}. In the upper panels of the LF-bigrams data and the consonants data in Figure \ref{fig:descriptives}A the data are visualised for each participant. In the respective lower panels of Figure \ref{fig:descriptives}A, different measures of central tendency are shown; and repeated for the IKI density functions in Figure \ref{fig:descriptives}B. 


```{r descriptives, fig.pos="!ht", fig.height = 7, fig.width = 6.5, fig.align = "center", fig.cap="Data overview. Panel A illustrates IKIs over bigrams position (time course) by participant in the upper rows and as different measures of central tendency (with standard error [SE]) in the lower rows for each the LF-bigrams task and the consonants task. Panel B shows the density distribution of IKI data with the same central tendency descriptors as in panel A."}

source("scripts/get_descriptives_plot.R")
plot_all
```


These visualisation highlight two important points: (1) aggregating data ignores individual time-course variability in the data; (2) the choice of central tendency measure might lead to different conclusions about patterns in the data. As for the first point, Figure \ref{fig:descriptives}A shows that participants slow down and speed up throughout the trial but do not show consistent patterns for the same letter bigrams as suggested in the corresponding summary statistics. Central tendency measures in the lower panels of Figure \ref{fig:descriptives}A suggest that some slowdowns and speedups might be bigram specific if we disregard by-participant variability. For example, in the LF-bigrams task, the first bigram is followed by a faster IKI; in the consonant task, the first bigram is followed by a IKI slowdown. Importantly though, there is a substantial variability between participants. 

As for the second point, the choice of central tendency measure might affect whether we consider an observation a disfluency. In particular, means are systematically longer than the median and mode. Figure \ref{fig:descriptives}B shows why this is the case. Shown are the density functions for the LF-bigrams and the consonants task. Both distributions are skewed (although log-scaled) with a heavy right tail. While in a normal distribution the mean, median and mode have identical values, the conceptual differences between these three measures of central tendency lead to different values in non-normal distributed data. In particular, means are known to be more sensitive to extreme values which are inevitable as IKIs are zero-bound but have, in principle, no upper bound. In other words, means are closer to the horizontal middle of the data space which, for right-skewed distributions, is on the right of the peak of the distribution (the value with the highest kernel density). The latter is being represented by the mode. Regardless of which measure is uesd, all three central tendency indicators ignore important properties of the distribution. That is, measures of central tendency neglect the variability in the data as expressed by distributions but also that the distribution of data might indeed come from a combination of processes; e.g. normal typing and disfluencies. Central tendency measures do not per se allow us to distinguish between IKIs that are the results of fluent typing and IKIs that reflect process lags. In sum, data aggregation does not just neglect participant-specific typing patterns but the choice of central tendency may lead to different conclusions about the data.



## Model fit

All models were implemented as Bayesian models [see e.g. @gelman2014; @lambert2018student; @mcelreath2016statistical] in the probabilistic programming language Stan [@carpenter2016stan; @rstan; @rstan2; @hoffman2014no]. Data, \textit{R}-scripts and \textit{Stan}-code are available on OSF ([doi.org/10.17605/OSF.IO/Y3P4D](https://doi.org/10.17605/OSF.IO/Y3P4D)). Models were fitted with 30,000 iterations (15,000 warm-up) on 3 MCMC chains. Convergence was tested via the Rubin-Gelman statistic [@gelman1992], traceplots and cross-validation [@vehtari2015pareto; @vehtari2017practical].

The predictive performance of the models was established using leave-one-out cross-validation. Cross-validation penalizes models with more parameters and therefore prevents overfit [see @farrell2018computational; @mcelreath2016statistical; @lambert2018student; @lee2014bayesian]. The out-of-sample predictive performance was determined via Pareto smoothed importance-sampling [@vehtari2015pareto; @vehtari2017practical] and estimated as sum of the expected log predictive density ($\widehat{elpd}$). $\widehat{elpd}$ was used to compare the predictive quality of our models. Model comparisons can be found in Table \ref{tab:modelcomparisons}. Model comparisons revealed higher predictive performance for models with mixture components. The combination of mixture components and autoregression as implemented in model M5 revealed a negligibly higher predictive performance over the mixture model M4 (see equation \ref{eq:mog}) for the consonants task. The latter showed higher predictive performance than all other models. As model M4 was simpler than model M5 but the predictive performance was similar, we preferred model M4 over model M5 for the consonants task. For LF-bigrams task, model 4 showed a higher predictive performance than all other models. We therefore chose model M4 for parameter evaluation of both copy-task components.



```{r modelcomparisons, results = "asis"}
source("scripts/get_loo_table.R")

papaja::apa_table(looc[-1],
                  align =  "lllrr",#c("l", "l", "l", "r", "r"), 
                  escape = FALSE, 
                  placement = "!ht",
#                  added_stub_head = "Copy-task component",
                  row.names = T,
                  stub_indents = list(`Consonants` = 1:5, `LF bigrams`= 6:10),
                  caption = "Model comparisons expressed as expected log predictive density ($\\widehat{elpd}$). The top row of each copy-task component shows the model with the highest predictive performance. Differences in predictive performance are shown as $\\Delta\\widehat{elpd}$ contrasting for each copy-task component the model in the first row and the remaining models. Standard errors (SE) are shown in brackets.",  
                  note = "LMM = linear mixed effects models; AR = Autoregressive model; MoG = Mixture of (log-)Gaussians"
) 

```


The second best performing model is the mixture model with the autoregressor $phi$ for fluent typing. In other words, adding the autoregressor instead of random bigram intercepts for fluent typing did not improve the predictive performance of the model. In fact, the autoregressive model was found to be the model with the lowest predictive performance. Modelling bigrams as random intercepts (with and without by-participant slope adjustments) was found to have a higher predictive performance compared to the autoregession model. 

```{r}
#source("scripts/get_posterior.R")
source("scripts/get_posterior_LF_cons.R")
```


## Parameter evaluation

The copy-typing process as expressed by the mixture model can be characterized with the posterior distributions of the model's parameter values. The process relevant parameters are illustrated in Figure \ref{fig:parameters}. Firstly, the modelled IKIs for fluent typing are shown in Figure \ref{fig:parameters}A. This figure captures the typing speed of each participant after accounting for typing disfluencies. Each horizontal line represents the statistically inferred estimate for one participant in the sample ordered from the fastest to the slowest typist for each copy-task separately. The pooled population estimate for fluent typing is `r round(beta_sum[1],0)` msecs embraced by a 95% probability interval (PI) with a lower bound of `r round(beta_sum[2],0)` and an upper bound of `r round(beta_sum[3],0)` for the consonants task and `r round(beta_sum[4],0)` msecs (95% PI: `r round(beta_sum[5],0)`, `r round(beta_sum[6],0)`) for the LF-bigrams task. Figure \ref{fig:parameters}B shows the disfluency probabilities. This parameter captures, for each participant, the probability to exhibit a typing disfluency. On the population level, the disfluency probability was found to be `r round(theta_sum[1],2)` (95% PI: `r round(theta_sum[2],2)`, `r round(theta_sum[3],2)`) for the consonants task but only `r round(theta_sum[5],2)` (95% PI: `r round(theta_sum[6],2)`,  `r round(theta_sum[7],2)`) for the LF-bigrams task. In other words, in the consonants task disfluent keystroke transitions are three times more likely than fluent transitions but in the LF-bigrams task, one out of three transitions consitutes a disfluency. For each participant the model captures varying pausing probabilities that express individual by also task-specific typing difficulty. Although on the population level disfluencies are more probable for the consonants task this is not the case for all participants (as indicated by individual estimates below 0.5 on the lower part of Figure \ref{fig:parameters}B).


```{r parameters, fig.pos="!ht", fig.height=6.5, fig.width=6.5, fig.align = "center", fig.cap="Parameter values of the mixture models for the LF-bigrams and the consonants task. Panel A shows the infered by-participant IKIs for fluent typing and Panel B shows the disfluency probabilities. Panel C shows estimates for fluent typing plotted against disfluency probability (black symboles indicate overall parameter values). Panel D shows the infered disfluency slowdown. All error bars are 95\\% probability intervals."}
source("scripts/get_posterior_plot2.R")
plot_post
```


Values in Figure \ref{fig:parameters}A and Figure \ref{fig:parameters}B are ordered for each task on the basis of the the most probable parameter. In other words, these two figures do not say anything about the relationship between fluent typing speed and disfluency probabilities. Figure \ref{fig:parameters}C illustrates this relationship. Shown are the parameter estimates for each participant and the overall pooled estimates (in black with 95% PIs). Figure \ref{fig:parameters}C suggests that individual typing speed and pausing disfluency are independent. In other words, fast as well as slow copy-typists can show low and high disfluency probabilities. Both parameter values show task sensitivity. The LF-bigrams task shows shorter typing intervals and a lower disfluency probability compared to the consonant task. Also, the between-participant variability for both parameters, fluent typing and disfluency probabilities, is larger in the consonants task than in the LF-bigrams task. This suggest that copy-typing strategies used by the participants are more diverse for the consonants task compared to the strategies used for the LF-bigrams task.

Lastly, the inferred slowdown parameter values for disfluent typing are shown in Figure \ref{fig:parameters}D. Disfluent typing was estimated to be `r delta_sum[1]` msecs (95% PI: `r delta_sum[2]`, `r delta_sum[3]`) slower than fluent typing in the consonant task and `r delta_sum[4]` msecs (95% PI: `r delta_sum[5]`, `r delta_sum[6]`) slower than fluent typing in the LF-bigrams task. In other words, the magnitude for disfluencies in the typing process is task-specific with shorter interruptions for the LF-bigrams task compared to the consonants task.

Faster participants might, in principle, show larger disfluency magnitudes; i.e. the size of the disfluency magnitude $\delta$ may vary by participant. To test this possibility we implemented two more models that are largly identical to model M4 (see equation \ref{eq:mog}): first, we allowed both the disfluency probability $\theta$ and the disfluency magnitude $\delta$ to vary by participant; second, $\delta$ but not $\theta$ was allowed to vary by participant. We compared the predictive performance of either model to model M4. Neither model was convincingly better than model M4, neither for the data from the consonants task nor for the data from the LF-bigrams task. For the consonants task, allowing $\delta$ and $\theta$ to vary by participant rendered a negligible gain over model M4 ($\Delta\widehat{elpd}$=`r abs(mc_cons$elpd_diff[1])`, SE=`r mc_cons$se_diff[1]`); holding the disfluency probability $\theta$ constant while allowing the disfluency magnitude $\delta$ to vary by participant revealed a lower predictive performance ($\Delta\widehat{elpd}$=`r mc_cons$elpd_diff[2]`, SE=`r mc_cons$se_diff[2]`). The same patterns was found for LF bigrams: allowing $\delta$ to vary rendered no gain in predictive performance ($\Delta\widehat{elpd}$=`r mc_lf$elpd_diff[1]`, SE=`r mc_lf$se_diff[1]`); fixing $\theta$ and allowing $\delta$ to vary showed a decrease in predictive performance ($\Delta\widehat{elpd}$=`r mc_lf$elpd_diff[2]`, SE=`r mc_lf$se_diff[2]`).



# Discussion

Our aim was to provide a statistical model that allows to address process disfluencies in keyboard-typing data in a principled manner. Inferring average typing speed requires a principled approach to account for disfluencies. We tested a series of Bayesian models on a lexical and a non-lexical component of the copy-task to address this aim. Model comparisons supported that process disfluencies can be captured best as a mixture process. This model allows us to extract reliable typing-interval estimates for fluent typing while accounting for process disfluencies by modelling fluent and disfluent typing as a combination of two distributions.


The best fitting model summarises the typing process as probability distributions of parameter values. There are three crutial parameter values provided by the model: first, the model provides population-level and by-participant estimates of fluent keystroke transitions; second, the model provides population-level and by-participant estimates of mixing proportions indicating the probability to observe disfluent keystroke transitions; third, the model provides a population-level estimate of the disfluency magnitude describing the slowdown in keystroke transitions of process disfluencies. These parameter estimates are interesting for two reasons: first, they allow us to characterize the writing task at hand as a mixture of fluent and disfluent keystroke transitions; second, by-participant parameter estimates allow us to extract characteristics for individual typists. Taken together with the overall and individual parameter estimates, we can determine whether an individual was a fast / slow typist or had unusually high / low probability to exhibit disfluencies compared to the population estimates. Thus, the model can be used diagnostically to identify participants with larger disfluency probabilities or to compare pausing across groups of participants.

The strength of the model with the highest predictive performance is that it allows to characterise the writing process in a principled way in line with what we know about keyboard typing. We achieved this my characterising the typing process as a mixture of fluent and disfluent keystroke transitions in which both typing speed and the proportion of disfluent tansitions depends on each typist's copying style. Not distinguishing between between fluent and disfluent keystroke transitions may lead to incorrect inference about fluent typing speed. For example, collapsing across fluent and disfluent transitions might lead to the conclusion that task related difficulty impacts on the execution of keystrokes even though overall increased keystroke transitions were in fact the results of more frequent and longer pauses. In particular only one-quarter of the data from the consonants task and two-thirds of the data from the LF-bigrams task were found to correspond to fluent keystroke transitions. Also, disfluencies in the consonants task were found to lead to a slowdown two times longer compared to LF-bigrams task. Even after accounting for disfluent keystroke transitions, fluent typing was still found to be two times slower in the consonants task compared to the LF-bgirams task. Not accounting for disfluencies would result in biased estimates affecting the task-related typing difference. 

Our results suggest that task related factors affected the probability and size of disfluencies in the consonants task. In the consonants task disfluencies are indeed more probable than fluent transitions. For the LF-bigrams task we observed a shorter disfluency difference associated with a lower probability than for fluent transitions. Across participants the probability of typing disfluencies was relatively similar in the LF-bigrams task but showed a larger variability in the consonants task. Similarly the average by-participant typing speed was more diverse in the consonants task compared to the LF-bigrams task. This contrast might be the result of a larger range of strategies that was used by the participants to copy consonants sequences than when copying the word triplet in the LF-bigrams task. These strategies may be understood as a function of typing skills and cognitive factors which is considered in the following.

The disfluency probability can be understood as an estimate for all non-typing related activities. As such it is an indicator of memory span [@grabowski2010second;@olive2014toward], low level reading skill [@de2018exploring] and individual typing skills. For example, in particular non-touch typists depend on memory resources to correctly copy the target string. This is because participants with poor typing skills have to shift gaze between keyboard and text more often than touch typists. Consequenty, memory resources are more important for poor typists such that participants with a shorter memory span might update their memory representation of the target string more frequently than participants with a long memory span expressed as an increased disfluency probability. Such memory limitations might impact less the typing performance of touch typists that do not require buffering of target letter(s) in memory while searching for the corresponding key(s). In contast, the lower variability found for the LF-bigrams task can be understood as more uniform copy-typing strategies across participants. Copy-typing strategies might have been more consistent for the LF-bigrams task because participants, especially those with poor typing skills, can make use existing knowledge (e.g. lexical meaning of words, motor codes for bigrams) to relief memory demands. This is not possible for the consonants task. However, we did not support a trade-off between typing speed and disfluency probabilities. This is because disfluencies are not merely the result of an update of the memory representation but may also be related to difficulty finding the right key. Also, depending on their memory span, participants may use varying strategies to chunk the target string, which then impacts on the disfluency probability.




The central advantage of using mixture models to account for typing disfluencies is that we can by-pass the use of threshold values to define disfluencies and include it as individual typing skill characteristic in the analysis of writing process data. Mixture models provide estimates for fluent typing while account for disfluencies by modelling fluent and disfluent typing as a mixture process. At the same time, mixture models provide disfluency estimates as expression for individual and task-specific typing difficulty. From raw data it is not possible to know which data are disfluencies. Using threshold values ignores that some participants are generally slower typists and some tasks are more difficult. Mixture models allow us to capture disfluencies as a latent process in a principled way. This is important because our mixture models take into account that a disfluency is relative to an individuals' typing speed and the task at hand [@wen06]. Therefore, these models allow us to test predictions about typing disfluencies in certain population such as learning typists, L2 typists and individuals with genuine typing difficulty after account for individual differences in typing speed or vice versa. In other words, the presented model can be used to test hypothesis about psychological factors (e.g. memory demands, writing experience, proficiency in writing in a second language) that might affect the ratio of disfluencies in the writing process. If disfluencies are crucial to identify certain individuals in a sample, this mixture model might also be used as diagnostic tool. Also, the provided mixture model  allows to directly test whether the number of disfluencies can be changed as response to an keyboard typing intervention. As an avenue for future research, mixture models as presented in this paper can be used for different types of writing tasks and particular populations.

Writing involves processing on various levels of mental representation. As activation cascades from higher to lower levels of representation, a delay on any of these levels causes disfluencies. While we distinguished fluent and disfluent typing in a binary way, processing difficulty on different levels might be associated with different disfluency magnitudes and might be cumulative. If the size of the disfluency is assumed to depend on the inhibited process upstream or combination of processes, this can be implemented as additional mixture component(s) [similar to @baaijen2012keystroke] to address different types of disfluencies [@medimorec2016effects; @medimorec2017disfluency; @wengelin2001disfluencies]. In other words extensions of mixture models allow us to test different hypotheses about the cascade of processes involved in writing and language production. 



# References
```{r create_r-references, echo=FALSE, include=FALSE}
r_refs(file = "ref.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
  
<div id = "ref"></div>
\endgroup
  


